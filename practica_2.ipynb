{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MHRJ5fOq0XlQ"
      },
      "source": [
        "# Importar dependencias"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Importación de librerías estándar de Python y PyTorch\n",
        "import os.path as osp\n",
        "import json\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Librerías de PyTorch y PyTorch Geometric\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.nn import Module, CrossEntropyLoss\n",
        "from torch.optim import Adam\n",
        "\n",
        "# Módulos de PyTorch Geometric\n",
        "from torch_geometric.nn import MLP, GCNConv, GATConv, GIN, GCN, SAGEConv\n",
        "from torch_geometric.data import InMemoryDataset, download_url\n",
        "\n",
        "# Utilidad para mostrar la arquitectura del modelo\n",
        "from torchsummary import summary\n",
        "\n",
        "# Métricas de evaluación\n",
        "from sklearn.metrics import confusion_matrix, f1_score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oywdRiO90dBy"
      },
      "source": [
        "# Cargar el dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.cuda.is_available()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "63VQAhc-zn8d"
      },
      "outputs": [],
      "source": [
        "class TournamentDataset(InMemoryDataset):\n",
        "\n",
        "    TORUNAMENT_URL = 'https://drive.upm.es/s/mnsESjBucKUKsEg/download'\n",
        "\n",
        "    def __init__(self, root, transform=None, pre_transform=None, pre_filter=None):\n",
        "        super().__init__(root, transform, pre_transform, pre_filter)\n",
        "        self.load(self.processed_paths[0])\n",
        "\n",
        "    @property\n",
        "    def raw_file_names(self):\n",
        "        return ['tournament.pt']\n",
        "\n",
        "    @property\n",
        "    def processed_file_names(self):\n",
        "        return ['tournament.pt']\n",
        "\n",
        "    @property\n",
        "    def num_classes(self):\n",
        "        return 3\n",
        "\n",
        "    @property\n",
        "    def num_features(self):\n",
        "        return 500\n",
        "\n",
        "    def download(self):\n",
        "        download_url(self.TORUNAMENT_URL, self.raw_dir, filename='tournament.pt')\n",
        "\n",
        "    def process(self):\n",
        "        data_list = [torch.load(osp.join(self.raw_dir, 'tournament.pt'))]\n",
        "\n",
        "        if self.pre_filter is not None:\n",
        "            data_list = [data for data in data_list if self.pre_filter(data)]\n",
        "\n",
        "        if self.pre_transform is not None:\n",
        "            data_list = [self.pre_transform(data) for data in data_list]\n",
        "\n",
        "        self.save(data_list, self.processed_paths[0])\n",
        "\n",
        "    def create_test_json(self, model, file_path, device=\"cpu\"):\n",
        "        data = self[0]\n",
        "\n",
        "        model = model.to(device)\n",
        "        data = data.to(device)\n",
        "\n",
        "        model.eval()\n",
        "        out = model(data.x, data.edge_index)\n",
        "        y_pred = out[data.test_mask].argmax(dim=1)\n",
        "        nid = data.nid[data.test_mask]\n",
        "\n",
        "        pred = {\n",
        "            'nid': nid.detach().cpu().numpy().tolist(),\n",
        "            'y': y_pred.detach().cpu().numpy().tolist()\n",
        "        }\n",
        "\n",
        "        with open(file_path, 'w') as f:\n",
        "            json.dump(pred, f)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BmhQysdi0B7O",
        "outputId": "d162c7b8-704a-4da8-ff02-540c3a0cc9e3"
      },
      "outputs": [],
      "source": [
        "dataset = TournamentDataset(\"tournament\")\n",
        "data = dataset[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(15970)\n",
            "tensor(1775)\n",
            "tensor(1972)\n"
          ]
        }
      ],
      "source": [
        "print(data.train_mask.sum())\n",
        "print(data.val_mask.sum())\n",
        "print(data.test_mask.sum())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hh4l8P3e0y7G"
      },
      "source": [
        "# Modelos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "f1_by_model = {}\n",
        "\n",
        "def train_model(model, model_name, dataset):\n",
        "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "    model = model.to(device)\n",
        "\n",
        "    optimizer = Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
        "    optm_func = CrossEntropyLoss()\n",
        "\n",
        "    data = dataset.to(device)\n",
        "\n",
        "    model.train()\n",
        "    for epoch in range(1000):\n",
        "        optimizer.zero_grad()\n",
        "        out = model(data.x, data.edge_index)\n",
        "        loss = optm_func(out[data.train_mask], data.y[data.train_mask].argmax(dim=1))\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if epoch % 10 == 0:\n",
        "            print(f\"Epoch {epoch}: Loss {loss.item()}\")\n",
        "\n",
        "    model.eval()\n",
        "    out = model(data.x, data.edge_index)\n",
        "\n",
        "    print(\"\\n\\nMODEL VALIDATION:\\n\")\n",
        "    y_pred = out.argmax(dim=1)[data.val_mask].detach().cpu()\n",
        "    y = data.y.argmax(dim=1)[data.val_mask].detach().cpu()\n",
        "\n",
        "    f1_val = f1_score(y, y_pred, average='micro')\n",
        "    print(f\"Validation F1 score: {f1_val}\")\n",
        "    # sns.heatmap(confusion_matrix(y, y_pred), annot=True, fmt='g', cmap='Blues');\n",
        "\n",
        "    print(\"\\n\\nMODEL TEST:\\n\")\n",
        "    y_pred = out.argmax(dim=1)[data.test_mask].detach().cpu()\n",
        "    y_pred = y_pred.numpy()\n",
        "    y = pd.read_csv('test_labels.csv')['y'].values\n",
        "    y = torch.tensor(y).cpu().numpy()\n",
        "    f1_test = f1_score(y, y_pred, average='micro')\n",
        "    print(f\"Test F1 score: {f1_test}\")\n",
        "\n",
        "    f1_by_model[model_name] = [f1_val, f1_test]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Baseline - MLP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==========================================================================================\n",
            "Layer (type:depth-idx)                   Output Shape              Param #\n",
            "==========================================================================================\n",
            "├─ModuleList: 1                          []                        --\n",
            "|    └─Linear: 2-1                       [-1, 32]                  16,032\n",
            "├─ModuleList: 1                          []                        --\n",
            "|    └─BatchNorm: 2-2                    [-1, 32]                  --\n",
            "|    |    └─BatchNorm1d: 3-1             [-1, 32]                  64\n",
            "├─ReLU: 1-1                              [-1, 32]                  --\n",
            "├─ModuleList: 1                          []                        --\n",
            "|    └─Linear: 2-3                       [-1, 3]                   99\n",
            "==========================================================================================\n",
            "Total params: 16,195\n",
            "Trainable params: 16,195\n",
            "Non-trainable params: 0\n",
            "Total mult-adds (M): 0.02\n",
            "==========================================================================================\n",
            "Input size (MB): 38.28\n",
            "Forward/backward pass size (MB): 0.00\n",
            "Params size (MB): 0.06\n",
            "Estimated Total Size (MB): 38.35\n",
            "==========================================================================================\n"
          ]
        }
      ],
      "source": [
        "model = MLP(\n",
        "    in_channels=dataset.num_node_features,\n",
        "    out_channels=dataset.num_classes,\n",
        "    num_layers=2,\n",
        "    hidden_channels=32\n",
        ")\n",
        "summary(model, (data.x, data.edge_index));"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 0: Loss 1.3579387664794922\n",
            "Epoch 10: Loss 0.4842308759689331\n",
            "Epoch 20: Loss 0.329582542181015\n",
            "Epoch 30: Loss 0.2640852928161621\n",
            "Epoch 40: Loss 0.22606459259986877\n",
            "Epoch 50: Loss 0.1959904134273529\n",
            "Epoch 60: Loss 0.16866092383861542\n",
            "Epoch 70: Loss 0.141808420419693\n",
            "Epoch 80: Loss 0.11581441015005112\n",
            "Epoch 90: Loss 0.0941544696688652\n",
            "Epoch 100: Loss 0.07386821508407593\n",
            "Epoch 110: Loss 0.05560578033328056\n",
            "Epoch 120: Loss 0.0432312898337841\n",
            "Epoch 130: Loss 0.039951059967279434\n",
            "Epoch 140: Loss 0.028671186417341232\n",
            "Epoch 150: Loss 0.02293195202946663\n",
            "Epoch 160: Loss 0.6288860440254211\n",
            "Epoch 170: Loss 0.16710802912712097\n",
            "Epoch 180: Loss 0.10295815020799637\n",
            "Epoch 190: Loss 0.06876469403505325\n",
            "Epoch 200: Loss 0.05146314576268196\n",
            "Epoch 210: Loss 0.038320280611515045\n",
            "Epoch 220: Loss 0.030399026349186897\n",
            "Epoch 230: Loss 0.024757705628871918\n",
            "Epoch 240: Loss 0.020814210176467896\n",
            "Epoch 250: Loss 0.017962131649255753\n",
            "Epoch 260: Loss 0.015867440029978752\n",
            "Epoch 270: Loss 0.014280589297413826\n",
            "Epoch 280: Loss 0.013031511567533016\n",
            "Epoch 290: Loss 0.012029527686536312\n",
            "Epoch 300: Loss 0.011206144466996193\n",
            "Epoch 310: Loss 0.010525406338274479\n",
            "Epoch 320: Loss 0.009950353763997555\n",
            "Epoch 330: Loss 0.00946281012147665\n",
            "Epoch 340: Loss 0.009040942415595055\n",
            "Epoch 350: Loss 0.008684261702001095\n",
            "Epoch 360: Loss 0.008387468755245209\n",
            "Epoch 370: Loss 0.008212540298700333\n",
            "Epoch 380: Loss 0.008032348938286304\n",
            "Epoch 390: Loss 0.0076125492341816425\n",
            "Epoch 400: Loss 0.0074461959302425385\n",
            "Epoch 410: Loss 0.013881505466997623\n",
            "Epoch 420: Loss 0.0087836729362607\n",
            "Epoch 430: Loss 0.007650178391486406\n",
            "Epoch 440: Loss 0.006989866960793734\n",
            "Epoch 450: Loss 0.006636005360633135\n",
            "Epoch 460: Loss 0.006442904472351074\n",
            "Epoch 470: Loss 0.006343563552945852\n",
            "Epoch 480: Loss 0.006275110878050327\n",
            "Epoch 490: Loss 0.006223734933882952\n",
            "Epoch 500: Loss 0.006190677639096975\n",
            "Epoch 510: Loss 0.006179237738251686\n",
            "Epoch 520: Loss 1.5871696472167969\n",
            "Epoch 530: Loss 0.28540945053100586\n",
            "Epoch 540: Loss 0.2111046463251114\n",
            "Epoch 550: Loss 0.1750931441783905\n",
            "Epoch 560: Loss 0.15024571120738983\n",
            "Epoch 570: Loss 0.12995028495788574\n",
            "Epoch 580: Loss 0.11274432390928268\n",
            "Epoch 590: Loss 0.09771532565355301\n",
            "Epoch 600: Loss 0.08469940721988678\n",
            "Epoch 610: Loss 0.07351391762495041\n",
            "Epoch 620: Loss 0.06391823291778564\n",
            "Epoch 630: Loss 0.05563880875706673\n",
            "Epoch 640: Loss 0.04851897805929184\n",
            "Epoch 650: Loss 0.042429495602846146\n",
            "Epoch 660: Loss 0.03718069940805435\n",
            "Epoch 670: Loss 0.032594017684459686\n",
            "Epoch 680: Loss 0.028637973591685295\n",
            "Epoch 690: Loss 0.025279736146330833\n",
            "Epoch 700: Loss 0.02246374450623989\n",
            "Epoch 710: Loss 0.020049000158905983\n",
            "Epoch 720: Loss 0.0180175993591547\n",
            "Epoch 730: Loss 0.01631995290517807\n",
            "Epoch 740: Loss 0.014907359145581722\n",
            "Epoch 750: Loss 0.0137101411819458\n",
            "Epoch 760: Loss 0.012647912837564945\n",
            "Epoch 770: Loss 0.011763075366616249\n",
            "Epoch 780: Loss 0.0110164824873209\n",
            "Epoch 790: Loss 0.010378309525549412\n",
            "Epoch 800: Loss 0.009837024845182896\n",
            "Epoch 810: Loss 0.009373690001666546\n",
            "Epoch 820: Loss 0.00895623303949833\n",
            "Epoch 830: Loss 0.008617803454399109\n",
            "Epoch 840: Loss 0.008289421908557415\n",
            "Epoch 850: Loss 0.008100218139588833\n",
            "Epoch 860: Loss 0.007842205464839935\n",
            "Epoch 870: Loss 0.007547186687588692\n",
            "Epoch 880: Loss 0.007432794664055109\n",
            "Epoch 890: Loss 0.007181550841778517\n",
            "Epoch 900: Loss 0.007045809645205736\n",
            "Epoch 910: Loss 0.006964328698813915\n",
            "Epoch 920: Loss 0.006747826933860779\n",
            "Epoch 930: Loss 0.006637669168412685\n",
            "Epoch 940: Loss 0.00668751448392868\n",
            "Epoch 950: Loss 0.00642193341627717\n",
            "Epoch 960: Loss 0.00647208746522665\n",
            "Epoch 970: Loss 0.00635435339063406\n",
            "Epoch 980: Loss 0.00615140562877059\n",
            "Epoch 990: Loss 0.0063124969601631165\n",
            "\n",
            "\n",
            "MODEL VALIDATION:\n",
            "\n",
            "Validation F1 score: 0.8523943661971831\n",
            "\n",
            "\n",
            "MODEL TEST:\n",
            "\n",
            "Test F1 score: 0.8575050709939148\n"
          ]
        }
      ],
      "source": [
        "train_model(model, \"MLP\", data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Aproximación I - GCNMLP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "Ftkl9IapUI5v"
      },
      "outputs": [],
      "source": [
        "class GCNMLP(Module):\n",
        "\n",
        "    def __init__(self, num_features, num_classes, hidden_channels=32, n_layers=2):\n",
        "        super(GCNMLP, self).__init__()\n",
        "        self.gcn = GCN(\n",
        "            in_channels=num_features,\n",
        "            hidden_channels=hidden_channels,\n",
        "            num_layers=n_layers,\n",
        "            out_channels=hidden_channels,\n",
        "        )\n",
        "        self.cls = MLP(\n",
        "            in_channels=hidden_channels,\n",
        "            hidden_channels=hidden_channels,\n",
        "            out_channels=num_classes,\n",
        "            num_layers=2,\n",
        "            dropout=0.5\n",
        "        )\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        self.gcn.reset_parameters()\n",
        "        self.cls.reset_parameters()\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        x = self.gcn(x, edge_index)\n",
        "        x = self.cls(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "VjsJmmx_02Ht"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "===============================================================================================\n",
            "Layer (type:depth-idx)                        Output Shape              Param #\n",
            "===============================================================================================\n",
            "├─GCN: 1-1                                    [-1, 48]                  --\n",
            "|    └─ModuleList: 2                          []                        --\n",
            "|    |    └─GCNConv: 3-1                      [-1, 48]                  24,048\n",
            "|    └─ModuleList: 2                          []                        --\n",
            "|    |    └─Identity: 3-2                     [-1, 48]                  --\n",
            "|    └─ReLU: 2-1                              [-1, 48]                  --\n",
            "|    └─Dropout: 2-2                           [-1, 48]                  --\n",
            "|    └─ModuleList: 2                          []                        --\n",
            "|    |    └─GCNConv: 3-3                      [-1, 48]                  2,352\n",
            "|    └─ModuleList: 2                          []                        --\n",
            "|    |    └─Identity: 3-4                     [-1, 48]                  --\n",
            "|    └─ReLU: 2-3                              [-1, 48]                  --\n",
            "|    └─Dropout: 2-4                           [-1, 48]                  --\n",
            "|    └─ModuleList: 2                          []                        --\n",
            "|    |    └─GCNConv: 3-5                      [-1, 48]                  2,352\n",
            "|    └─ModuleList: 2                          []                        --\n",
            "|    |    └─Identity: 3-6                     [-1, 48]                  --\n",
            "|    └─ReLU: 2-5                              [-1, 48]                  --\n",
            "|    └─Dropout: 2-6                           [-1, 48]                  --\n",
            "|    └─ModuleList: 2                          []                        --\n",
            "|    |    └─GCNConv: 3-7                      [-1, 48]                  2,352\n",
            "|    └─ModuleList: 2                          []                        --\n",
            "|    |    └─Identity: 3-8                     [-1, 48]                  --\n",
            "|    └─ReLU: 2-7                              [-1, 48]                  --\n",
            "|    └─Dropout: 2-8                           [-1, 48]                  --\n",
            "|    └─ModuleList: 2                          []                        --\n",
            "|    |    └─GCNConv: 3-9                      [-1, 48]                  2,352\n",
            "├─MLP: 1-2                                    [-1, 3]                   --\n",
            "|    └─ModuleList: 2                          []                        --\n",
            "|    |    └─Linear: 3-10                      [-1, 48]                  2,352\n",
            "|    └─ModuleList: 2                          []                        --\n",
            "|    |    └─BatchNorm: 3-11                   [-1, 48]                  96\n",
            "|    └─ReLU: 2-9                              [-1, 48]                  --\n",
            "|    └─ModuleList: 2                          []                        --\n",
            "|    |    └─Linear: 3-12                      [-1, 3]                   147\n",
            "===============================================================================================\n",
            "Total params: 36,051\n",
            "Trainable params: 36,051\n",
            "Non-trainable params: 0\n",
            "Total mult-adds (M): 0.10\n",
            "===============================================================================================\n",
            "Input size (MB): 38.28\n",
            "Forward/backward pass size (MB): 0.00\n",
            "Params size (MB): 0.14\n",
            "Estimated Total Size (MB): 38.42\n",
            "===============================================================================================\n"
          ]
        }
      ],
      "source": [
        "model = GCNMLP(\n",
        "    dataset.num_node_features,\n",
        "    dataset.num_classes,\n",
        "    hidden_channels=48,\n",
        "    n_layers=5\n",
        ")\n",
        "\n",
        "model.reset_parameters()\n",
        "\n",
        "summary(model, (data.x, data.edge_index));"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 0: Loss 1.2144372463226318\n",
            "Epoch 10: Loss 0.48101678490638733\n",
            "Epoch 20: Loss 0.42964664101600647\n",
            "Epoch 30: Loss 0.4043819010257721\n",
            "Epoch 40: Loss 0.3879830241203308\n",
            "Epoch 50: Loss 0.3747926652431488\n",
            "Epoch 60: Loss 0.3647252917289734\n",
            "Epoch 70: Loss 0.35730183124542236\n",
            "Epoch 80: Loss 0.3443533480167389\n",
            "Epoch 90: Loss 0.33203431963920593\n",
            "Epoch 100: Loss 0.34967562556266785\n",
            "Epoch 110: Loss 0.3281095027923584\n",
            "Epoch 120: Loss 0.3158959150314331\n",
            "Epoch 130: Loss 0.30947256088256836\n",
            "Epoch 140: Loss 0.2939211130142212\n",
            "Epoch 150: Loss 0.2596166133880615\n",
            "Epoch 160: Loss 0.3367003798484802\n",
            "Epoch 170: Loss 0.30592796206474304\n",
            "Epoch 180: Loss 0.254535973072052\n",
            "Epoch 190: Loss 0.22869090735912323\n",
            "Epoch 200: Loss 0.19490349292755127\n",
            "Epoch 210: Loss 0.17414900660514832\n",
            "Epoch 220: Loss 0.16637283563613892\n",
            "Epoch 230: Loss 0.1402612030506134\n",
            "Epoch 240: Loss 0.32643166184425354\n",
            "Epoch 250: Loss 0.25878989696502686\n",
            "Epoch 260: Loss 0.21289464831352234\n",
            "Epoch 270: Loss 0.1712133139371872\n",
            "Epoch 280: Loss 0.15500709414482117\n",
            "Epoch 290: Loss 0.13631416857242584\n",
            "Epoch 300: Loss 0.12768493592739105\n",
            "Epoch 310: Loss 0.13357789814472198\n",
            "Epoch 320: Loss 0.22816886007785797\n",
            "Epoch 330: Loss 0.17623399198055267\n",
            "Epoch 340: Loss 0.1418256163597107\n",
            "Epoch 350: Loss 0.11957234144210815\n",
            "Epoch 360: Loss 0.11405128240585327\n",
            "Epoch 370: Loss 0.16217149794101715\n",
            "Epoch 380: Loss 0.13140718638896942\n",
            "Epoch 390: Loss 0.10732224583625793\n",
            "Epoch 400: Loss 0.09910137206315994\n",
            "Epoch 410: Loss 0.08627057075500488\n",
            "Epoch 420: Loss 0.0916438177227974\n",
            "Epoch 430: Loss 0.18307432532310486\n",
            "Epoch 440: Loss 0.10936395078897476\n",
            "Epoch 450: Loss 0.08986315876245499\n",
            "Epoch 460: Loss 0.07847851514816284\n",
            "Epoch 470: Loss 0.08811727166175842\n",
            "Epoch 480: Loss 0.08065791428089142\n",
            "Epoch 490: Loss 0.08133862912654877\n",
            "Epoch 500: Loss 0.13453081250190735\n",
            "Epoch 510: Loss 0.12139209359884262\n",
            "Epoch 520: Loss 0.0885034054517746\n",
            "Epoch 530: Loss 0.07479378581047058\n",
            "Epoch 540: Loss 0.0667114332318306\n",
            "Epoch 550: Loss 0.06054271385073662\n",
            "Epoch 560: Loss 0.06277602910995483\n",
            "Epoch 570: Loss 0.06931760907173157\n",
            "Epoch 580: Loss 0.4393543303012848\n",
            "Epoch 590: Loss 0.21244095265865326\n",
            "Epoch 600: Loss 0.14475134015083313\n",
            "Epoch 610: Loss 0.1140376552939415\n",
            "Epoch 620: Loss 0.0940980464220047\n",
            "Epoch 630: Loss 0.08204716444015503\n",
            "Epoch 640: Loss 0.07401587069034576\n",
            "Epoch 650: Loss 0.07329621911048889\n",
            "Epoch 660: Loss 0.06719385087490082\n",
            "Epoch 670: Loss 0.07281388342380524\n",
            "Epoch 680: Loss 0.278022438287735\n",
            "Epoch 690: Loss 0.18579019606113434\n",
            "Epoch 700: Loss 0.13171839714050293\n",
            "Epoch 710: Loss 0.10443437844514847\n",
            "Epoch 720: Loss 0.08888603746891022\n",
            "Epoch 730: Loss 0.07771888375282288\n",
            "Epoch 740: Loss 0.0726800262928009\n",
            "Epoch 750: Loss 0.07003926485776901\n",
            "Epoch 760: Loss 0.06993506103754044\n",
            "Epoch 770: Loss 0.0626022145152092\n",
            "Epoch 780: Loss 0.05929939076304436\n",
            "Epoch 790: Loss 0.05554301291704178\n",
            "Epoch 800: Loss 0.12174687534570694\n",
            "Epoch 810: Loss 0.09709319472312927\n",
            "Epoch 820: Loss 0.0737156793475151\n",
            "Epoch 830: Loss 0.06102826073765755\n",
            "Epoch 840: Loss 0.057604335248470306\n",
            "Epoch 850: Loss 0.05517148971557617\n",
            "Epoch 860: Loss 0.2697729170322418\n",
            "Epoch 870: Loss 0.18078374862670898\n",
            "Epoch 880: Loss 0.13827668130397797\n",
            "Epoch 890: Loss 0.10622141510248184\n",
            "Epoch 900: Loss 0.08566794544458389\n",
            "Epoch 910: Loss 0.07794089615345001\n",
            "Epoch 920: Loss 0.06920617073774338\n",
            "Epoch 930: Loss 0.0614825040102005\n",
            "Epoch 940: Loss 0.061591487377882004\n",
            "Epoch 950: Loss 0.06956979632377625\n",
            "Epoch 960: Loss 0.06248961016535759\n",
            "Epoch 970: Loss 0.05452094227075577\n",
            "Epoch 980: Loss 0.25161537528038025\n",
            "Epoch 990: Loss 0.14897827804088593\n",
            "\n",
            "\n",
            "MODEL VALIDATION:\n",
            "\n",
            "Validation F1 score: 0.8343661971830986\n",
            "\n",
            "\n",
            "MODEL TEST:\n",
            "\n",
            "Test F1 score: 0.8427991886409736\n"
          ]
        }
      ],
      "source": [
        "train_model(model, \"GCNMLP\", data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Aproximación II - GINMLP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "zFgcYv9nU9Hn"
      },
      "outputs": [],
      "source": [
        "class GINMLP(Module):\n",
        "\n",
        "    def __init__(self, num_features, num_classes, hidden_channels=32, n_layers=2):\n",
        "        super(GINMLP, self).__init__()\n",
        "        self.gcn = GIN(\n",
        "            in_channels=num_features,\n",
        "            hidden_channels=hidden_channels,\n",
        "            num_layers=n_layers,\n",
        "            out_channels=hidden_channels,\n",
        "            dropout=0.5,\n",
        "            act=\"relu\",\n",
        "            jk=\"cat\"\n",
        "        )\n",
        "        self.cls = MLP(\n",
        "            in_channels=hidden_channels,\n",
        "            hidden_channels=hidden_channels,\n",
        "            out_channels=num_classes,\n",
        "            num_layers=2,\n",
        "            dropout=0.5\n",
        "        )\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        self.gcn.reset_parameters()\n",
        "        self.cls.reset_parameters()\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        x = self.gcn(x, edge_index)\n",
        "        x = self.cls(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "pSSr2o0pVESE"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==========================================================================================\n",
            "Layer (type:depth-idx)                   Output Shape              Param #\n",
            "==========================================================================================\n",
            "├─GIN: 1-1                               [-1, 32]                  --\n",
            "|    └─ModuleList: 2                     []                        --\n",
            "|    |    └─GINConv: 3-1                 [-1, 32]                  17,088\n",
            "|    └─ReLU: 2-1                         [-1, 32]                  --\n",
            "|    └─ModuleList: 2                     []                        --\n",
            "|    |    └─Identity: 3-2                [-1, 32]                  --\n",
            "|    └─ReLU: 2-2                         [-1, 32]                  --\n",
            "|    └─Dropout: 2-3                      [-1, 32]                  --\n",
            "|    └─ModuleList: 2                     []                        --\n",
            "|    |    └─GINConv: 3-3                 [-1, 32]                  2,112\n",
            "|    └─ReLU: 2-4                         [-1, 32]                  --\n",
            "|    └─ModuleList: 2                     []                        --\n",
            "|    |    └─Identity: 3-4                [-1, 32]                  --\n",
            "|    └─ReLU: 2-5                         [-1, 32]                  --\n",
            "|    └─Dropout: 2-6                      [-1, 32]                  --\n",
            "|    └─ModuleList: 2                     []                        --\n",
            "|    |    └─GINConv: 3-5                 [-1, 32]                  2,112\n",
            "|    └─ReLU: 2-7                         [-1, 32]                  --\n",
            "|    └─ModuleList: 2                     []                        --\n",
            "|    |    └─Identity: 3-6                [-1, 32]                  --\n",
            "|    └─ReLU: 2-8                         [-1, 32]                  --\n",
            "|    └─Dropout: 2-9                      [-1, 32]                  --\n",
            "|    └─JumpingKnowledge: 2-10            [-1, 96]                  --\n",
            "|    └─Linear: 2-11                      [-1, 32]                  3,104\n",
            "├─MLP: 1-2                               [-1, 3]                   --\n",
            "|    └─ModuleList: 2                     []                        --\n",
            "|    |    └─Linear: 3-7                  [-1, 32]                  1,056\n",
            "|    └─ModuleList: 2                     []                        --\n",
            "|    |    └─BatchNorm: 3-8               [-1, 32]                  64\n",
            "|    └─ReLU: 2-12                        [-1, 32]                  --\n",
            "|    └─ModuleList: 2                     []                        --\n",
            "|    |    └─Linear: 3-9                  [-1, 3]                   99\n",
            "==========================================================================================\n",
            "Total params: 25,635\n",
            "Trainable params: 25,635\n",
            "Non-trainable params: 0\n",
            "Total mult-adds (M): 0.07\n",
            "==========================================================================================\n",
            "Input size (MB): 38.28\n",
            "Forward/backward pass size (MB): 0.00\n",
            "Params size (MB): 0.10\n",
            "Estimated Total Size (MB): 38.38\n",
            "==========================================================================================\n"
          ]
        }
      ],
      "source": [
        "model = GINMLP(\n",
        "    dataset.num_node_features,\n",
        "    dataset.num_classes,\n",
        "    hidden_channels=32,\n",
        "    n_layers=3\n",
        ")\n",
        "\n",
        "model.reset_parameters()\n",
        "\n",
        "summary(model, (data.x, data.edge_index));"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 0: Loss 1.1192479133605957\n",
            "Epoch 10: Loss 0.9757670760154724\n",
            "Epoch 20: Loss 0.827665388584137\n",
            "Epoch 30: Loss 0.7656267881393433\n",
            "Epoch 40: Loss 0.7120621204376221\n",
            "Epoch 50: Loss 0.6663424372673035\n",
            "Epoch 60: Loss 0.5981178879737854\n",
            "Epoch 70: Loss 0.5055944323539734\n",
            "Epoch 80: Loss 0.42547187209129333\n",
            "Epoch 90: Loss 0.3813863694667816\n",
            "Epoch 100: Loss 0.34702062606811523\n",
            "Epoch 110: Loss 0.3180527091026306\n",
            "Epoch 120: Loss 0.31045636534690857\n",
            "Epoch 130: Loss 0.27108994126319885\n",
            "Epoch 140: Loss 0.24622303247451782\n",
            "Epoch 150: Loss 0.263576477766037\n",
            "Epoch 160: Loss 0.23214522004127502\n",
            "Epoch 170: Loss 0.20200297236442566\n",
            "Epoch 180: Loss 0.1946658194065094\n",
            "Epoch 190: Loss 0.19588474929332733\n",
            "Epoch 200: Loss 0.1778413951396942\n",
            "Epoch 210: Loss 0.20484904944896698\n",
            "Epoch 220: Loss 0.1744355410337448\n",
            "Epoch 230: Loss 0.15467755496501923\n",
            "Epoch 240: Loss 0.1456914097070694\n",
            "Epoch 250: Loss 0.1368647813796997\n",
            "Epoch 260: Loss 0.12953510880470276\n",
            "Epoch 270: Loss 0.13619747757911682\n",
            "Epoch 280: Loss 0.13412289321422577\n",
            "Epoch 290: Loss 0.1359444260597229\n",
            "Epoch 300: Loss 0.12785714864730835\n",
            "Epoch 310: Loss 0.13118238747119904\n",
            "Epoch 320: Loss 0.13170121610164642\n",
            "Epoch 330: Loss 0.12323582172393799\n",
            "Epoch 340: Loss 0.11158455163240433\n",
            "Epoch 350: Loss 0.10654539614915848\n",
            "Epoch 360: Loss 0.11318691819906235\n",
            "Epoch 370: Loss 0.1112905740737915\n",
            "Epoch 380: Loss 0.1314285695552826\n",
            "Epoch 390: Loss 0.12935525178909302\n",
            "Epoch 400: Loss 0.10904053598642349\n",
            "Epoch 410: Loss 0.10545679926872253\n",
            "Epoch 420: Loss 0.11152663081884384\n",
            "Epoch 430: Loss 0.11647968739271164\n",
            "Epoch 440: Loss 0.11900361627340317\n",
            "Epoch 450: Loss 0.10444740951061249\n",
            "Epoch 460: Loss 0.10552547872066498\n",
            "Epoch 470: Loss 0.09665540605783463\n",
            "Epoch 480: Loss 0.08999275416135788\n",
            "Epoch 490: Loss 0.08693201094865799\n",
            "Epoch 500: Loss 0.09504970908164978\n",
            "Epoch 510: Loss 0.364071786403656\n",
            "Epoch 520: Loss 0.19865785539150238\n",
            "Epoch 530: Loss 0.15195927023887634\n",
            "Epoch 540: Loss 0.1223401203751564\n",
            "Epoch 550: Loss 0.09986621141433716\n",
            "Epoch 560: Loss 0.10687550902366638\n",
            "Epoch 570: Loss 0.09417767077684402\n",
            "Epoch 580: Loss 0.08943216502666473\n",
            "Epoch 590: Loss 0.09103591740131378\n",
            "Epoch 600: Loss 0.09954214096069336\n",
            "Epoch 610: Loss 0.11338717490434647\n",
            "Epoch 620: Loss 0.1323581039905548\n",
            "Epoch 630: Loss 0.10849489271640778\n",
            "Epoch 640: Loss 0.08978674560785294\n",
            "Epoch 650: Loss 0.08798757940530777\n",
            "Epoch 660: Loss 0.09286153316497803\n",
            "Epoch 670: Loss 0.08865533769130707\n",
            "Epoch 680: Loss 0.13259634375572205\n",
            "Epoch 690: Loss 0.08796747028827667\n",
            "Epoch 700: Loss 0.08564260601997375\n",
            "Epoch 710: Loss 0.08365165442228317\n",
            "Epoch 720: Loss 0.07520949095487595\n",
            "Epoch 730: Loss 0.0875578224658966\n",
            "Epoch 740: Loss 0.07987712323665619\n",
            "Epoch 750: Loss 0.08949718624353409\n",
            "Epoch 760: Loss 0.10123754292726517\n",
            "Epoch 770: Loss 0.08464884757995605\n",
            "Epoch 780: Loss 0.08108559995889664\n",
            "Epoch 790: Loss 0.0728430524468422\n",
            "Epoch 800: Loss 0.10142163932323456\n",
            "Epoch 810: Loss 0.11566394567489624\n",
            "Epoch 820: Loss 0.24511969089508057\n",
            "Epoch 830: Loss 0.13715696334838867\n",
            "Epoch 840: Loss 0.09882286190986633\n",
            "Epoch 850: Loss 0.08729550242424011\n",
            "Epoch 860: Loss 0.08150870352983475\n",
            "Epoch 870: Loss 0.0749220922589302\n",
            "Epoch 880: Loss 0.07982303202152252\n",
            "Epoch 890: Loss 0.09084180742502213\n",
            "Epoch 900: Loss 0.09077585488557816\n",
            "Epoch 910: Loss 0.07162173092365265\n",
            "Epoch 920: Loss 0.07920948415994644\n",
            "Epoch 930: Loss 0.0708870068192482\n",
            "Epoch 940: Loss 0.07351366430521011\n",
            "Epoch 950: Loss 0.07263938337564468\n",
            "Epoch 960: Loss 0.07592210918664932\n",
            "Epoch 970: Loss 0.08345669507980347\n",
            "Epoch 980: Loss 0.10383288562297821\n",
            "Epoch 990: Loss 0.104181207716465\n",
            "\n",
            "\n",
            "MODEL VALIDATION:\n",
            "\n",
            "Validation F1 score: 0.8501408450704225\n",
            "\n",
            "\n",
            "MODEL TEST:\n",
            "\n",
            "Test F1 score: 0.8580121703853956\n"
          ]
        }
      ],
      "source": [
        "train_model(model, \"GINMLP\", data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Aproximación III - Convolucional"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "tiEH1JK_XLm7"
      },
      "outputs": [],
      "source": [
        "class Convolucional(nn.Module):\n",
        "    def __init__(self, in_channels, hidden_channels, out_channels, dropout_rate=0.5):\n",
        "        super(Convolucional, self).__init__()\n",
        "\n",
        "        self.dropout_rate = dropout_rate\n",
        "\n",
        "        # Capas de GNN\n",
        "        self.gcn1 = GCNConv(in_channels, hidden_channels)\n",
        "        self.gcn2 = GCNConv(hidden_channels, hidden_channels)\n",
        "        self.gat = GATConv(hidden_channels, hidden_channels, heads=8, concat=False)\n",
        "        self.gcn3 = GCNConv(hidden_channels, hidden_channels)\n",
        "\n",
        "        # Capas densas (más profundas)\n",
        "        self.fc1 = nn.Linear(hidden_channels, hidden_channels // 2)\n",
        "        self.fc2 = nn.Linear(hidden_channels // 2, hidden_channels // 4)\n",
        "        self.fc3 = nn.Linear(hidden_channels // 4, hidden_channels // 8)\n",
        "        self.fc4 = nn.Linear(hidden_channels // 8, out_channels)\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        # Capas GCN y GAT\n",
        "        x = F.relu(self.gcn1(x, edge_index))\n",
        "        x = F.dropout(x, p=self.dropout_rate, training=self.training)\n",
        "\n",
        "        x = F.relu(self.gcn2(x, edge_index))\n",
        "        x = F.dropout(x, p=self.dropout_rate, training=self.training)\n",
        "\n",
        "        x = F.relu(self.gat(x, edge_index))\n",
        "        x = F.dropout(x, p=self.dropout_rate, training=self.training)\n",
        "\n",
        "        x = F.relu(self.gcn3(x, edge_index))\n",
        "        x = F.dropout(x, p=self.dropout_rate, training=self.training)\n",
        "\n",
        "        # Capas densas finales\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.dropout(x, p=self.dropout_rate, training=self.training)\n",
        "\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = F.dropout(x, p=self.dropout_rate, training=self.training)\n",
        "\n",
        "        x = F.relu(self.fc3(x))\n",
        "        x = F.dropout(x, p=self.dropout_rate, training=self.training)\n",
        "\n",
        "        x = self.fc4(x)  # Capa final sin activación, log-softmax al final\n",
        "\n",
        "        return x.log_softmax(dim=-1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "ee7K0WCBXN0B"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==========================================================================================\n",
            "Layer (type:depth-idx)                   Output Shape              Param #\n",
            "==========================================================================================\n",
            "├─GCNConv: 1-1                           [-1, 64]                  --\n",
            "|    └─Linear: 2-1                       [-1, 64]                  32,000\n",
            "|    └─SumAggregation: 2-2               [-1, 64]                  --\n",
            "├─GCNConv: 1-2                           [-1, 64]                  --\n",
            "|    └─Linear: 2-3                       [-1, 64]                  4,096\n",
            "|    └─SumAggregation: 2-4               [-1, 64]                  --\n",
            "├─GATConv: 1-3                           [-1, 64]                  --\n",
            "|    └─Linear: 2-5                       [-1, 512]                 32,768\n",
            "|    └─SumAggregation: 2-6               [-1, 8, 64]               --\n",
            "├─GCNConv: 1-4                           [-1, 64]                  --\n",
            "|    └─Linear: 2-7                       [-1, 64]                  4,096\n",
            "|    └─SumAggregation: 2-8               [-1, 64]                  --\n",
            "├─Linear: 1-5                            [-1, 32]                  2,080\n",
            "├─Linear: 1-6                            [-1, 16]                  528\n",
            "├─Linear: 1-7                            [-1, 8]                   136\n",
            "├─Linear: 1-8                            [-1, 3]                   27\n",
            "==========================================================================================\n",
            "Total params: 75,731\n",
            "Trainable params: 75,731\n",
            "Non-trainable params: 0\n",
            "Total mult-adds (M): 0.15\n",
            "==========================================================================================\n",
            "Input size (MB): 38.28\n",
            "Forward/backward pass size (MB): 0.01\n",
            "Params size (MB): 0.29\n",
            "Estimated Total Size (MB): 38.58\n",
            "==========================================================================================\n"
          ]
        }
      ],
      "source": [
        "model = Convolucional(\n",
        "    dataset.num_node_features,\n",
        "    64,\n",
        "    dataset.num_classes\n",
        ")\n",
        "\n",
        "summary(model, (data.x, data.edge_index));"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 0: Loss 1.1379339694976807\n",
            "Epoch 10: Loss 1.0825361013412476\n",
            "Epoch 20: Loss 0.9564608335494995\n",
            "Epoch 30: Loss 0.8567831516265869\n",
            "Epoch 40: Loss 0.8158344626426697\n",
            "Epoch 50: Loss 0.7831470966339111\n",
            "Epoch 60: Loss 0.7588058710098267\n",
            "Epoch 70: Loss 0.7376648187637329\n",
            "Epoch 80: Loss 0.716252326965332\n",
            "Epoch 90: Loss 0.6751753091812134\n",
            "Epoch 100: Loss 0.6456558704376221\n",
            "Epoch 110: Loss 0.632782518863678\n",
            "Epoch 120: Loss 0.6329590678215027\n",
            "Epoch 130: Loss 0.6253604888916016\n",
            "Epoch 140: Loss 0.7711410522460938\n",
            "Epoch 150: Loss 0.6885467767715454\n",
            "Epoch 160: Loss 0.6568063497543335\n",
            "Epoch 170: Loss 0.6294886469841003\n",
            "Epoch 180: Loss 0.61507648229599\n",
            "Epoch 190: Loss 0.6041634678840637\n",
            "Epoch 200: Loss 0.5858628749847412\n",
            "Epoch 210: Loss 0.602570652961731\n",
            "Epoch 220: Loss 0.6255032420158386\n",
            "Epoch 230: Loss 0.574266791343689\n",
            "Epoch 240: Loss 0.5583333373069763\n",
            "Epoch 250: Loss 0.5630202889442444\n",
            "Epoch 260: Loss 0.6980453133583069\n",
            "Epoch 270: Loss 0.6198546886444092\n",
            "Epoch 280: Loss 0.5863429307937622\n",
            "Epoch 290: Loss 0.5453715324401855\n",
            "Epoch 300: Loss 0.5538633465766907\n",
            "Epoch 310: Loss 0.5884715914726257\n",
            "Epoch 320: Loss 0.6056171655654907\n",
            "Epoch 330: Loss 0.540083646774292\n",
            "Epoch 340: Loss 0.523618221282959\n",
            "Epoch 350: Loss 0.5273668766021729\n",
            "Epoch 360: Loss 0.5207695364952087\n",
            "Epoch 370: Loss 0.5350072979927063\n",
            "Epoch 380: Loss 0.5491114854812622\n",
            "Epoch 390: Loss 0.5090084671974182\n",
            "Epoch 400: Loss 0.553678572177887\n",
            "Epoch 410: Loss 0.523826539516449\n",
            "Epoch 420: Loss 0.5045854449272156\n",
            "Epoch 430: Loss 0.5052675008773804\n",
            "Epoch 440: Loss 0.5104196071624756\n",
            "Epoch 450: Loss 0.4835106432437897\n",
            "Epoch 460: Loss 0.4908543825149536\n",
            "Epoch 470: Loss 0.4983316659927368\n",
            "Epoch 480: Loss 0.5099916458129883\n",
            "Epoch 490: Loss 0.5127838850021362\n",
            "Epoch 500: Loss 0.496353417634964\n",
            "Epoch 510: Loss 0.6204460263252258\n",
            "Epoch 520: Loss 0.5330861210823059\n",
            "Epoch 530: Loss 0.5084317922592163\n",
            "Epoch 540: Loss 0.49599704146385193\n",
            "Epoch 550: Loss 0.48880910873413086\n",
            "Epoch 560: Loss 0.480803519487381\n",
            "Epoch 570: Loss 0.4959909915924072\n",
            "Epoch 580: Loss 0.48963063955307007\n",
            "Epoch 590: Loss 0.48573100566864014\n",
            "Epoch 600: Loss 0.5117359161376953\n",
            "Epoch 610: Loss 0.5201705098152161\n",
            "Epoch 620: Loss 0.5610992312431335\n",
            "Epoch 630: Loss 0.4905976951122284\n",
            "Epoch 640: Loss 0.5018792748451233\n",
            "Epoch 650: Loss 0.4765889048576355\n",
            "Epoch 660: Loss 0.4789791405200958\n",
            "Epoch 670: Loss 0.5065343379974365\n",
            "Epoch 680: Loss 0.4836735725402832\n",
            "Epoch 690: Loss 0.48053857684135437\n",
            "Epoch 700: Loss 0.4794245958328247\n",
            "Epoch 710: Loss 0.4787718951702118\n",
            "Epoch 720: Loss 0.45895645022392273\n",
            "Epoch 730: Loss 0.49628621339797974\n",
            "Epoch 740: Loss 0.505668044090271\n",
            "Epoch 750: Loss 0.5087579488754272\n",
            "Epoch 760: Loss 0.49392953515052795\n",
            "Epoch 770: Loss 0.48408305644989014\n",
            "Epoch 780: Loss 0.46554192900657654\n",
            "Epoch 790: Loss 0.4721856415271759\n",
            "Epoch 800: Loss 0.4660860300064087\n",
            "Epoch 810: Loss 0.5171738266944885\n",
            "Epoch 820: Loss 0.49665865302085876\n",
            "Epoch 830: Loss 0.48860254883766174\n",
            "Epoch 840: Loss 0.48528584837913513\n",
            "Epoch 850: Loss 0.4946812093257904\n",
            "Epoch 860: Loss 0.4534263014793396\n",
            "Epoch 870: Loss 0.47029006481170654\n",
            "Epoch 880: Loss 0.49005040526390076\n",
            "Epoch 890: Loss 0.4757494628429413\n",
            "Epoch 900: Loss 0.4660246968269348\n",
            "Epoch 910: Loss 0.4644292891025543\n",
            "Epoch 920: Loss 0.4797726273536682\n",
            "Epoch 930: Loss 0.48768043518066406\n",
            "Epoch 940: Loss 0.5024866461753845\n",
            "Epoch 950: Loss 0.4986935555934906\n",
            "Epoch 960: Loss 0.515238344669342\n",
            "Epoch 970: Loss 0.4962913691997528\n",
            "Epoch 980: Loss 0.4791695773601532\n",
            "Epoch 990: Loss 0.46008336544036865\n",
            "\n",
            "\n",
            "MODEL VALIDATION:\n",
            "\n",
            "Validation F1 score: 0.8276056338028169\n",
            "\n",
            "\n",
            "MODEL TEST:\n",
            "\n",
            "Test F1 score: 0.8377281947261663\n"
          ]
        }
      ],
      "source": [
        "train_model(model, \"Convolucional\", data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "f2dKfGRkczks"
      },
      "outputs": [],
      "source": [
        "class Convolucional_Softmax(nn.Module):\n",
        "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
        "        super(Convolucional_Softmax, self).__init__()\n",
        "        self.gcn1 = GCNConv(in_channels, hidden_channels)\n",
        "        self.gat = GATConv(hidden_channels, hidden_channels, heads=3, concat=False)\n",
        "        self.gcn2 = GCNConv(hidden_channels, hidden_channels)\n",
        "        self.fc = nn.Linear(hidden_channels, out_channels)\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        # Primera capa GCN\n",
        "        x = F.relu(self.gcn1(x, edge_index))\n",
        "        # Atención con GAT\n",
        "        x = F.relu(self.gat(x, edge_index))\n",
        "        # Segunda capa GCN\n",
        "        x = F.relu(self.gcn2(x, edge_index))\n",
        "        # Clasificación final\n",
        "        x = self.fc(x)\n",
        "        return F.log_softmax(x, dim=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "yD0XNjJvc0ki"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==========================================================================================\n",
            "Layer (type:depth-idx)                   Output Shape              Param #\n",
            "==========================================================================================\n",
            "├─GCNConv: 1-1                           [-1, 1024]                --\n",
            "|    └─Linear: 2-1                       [-1, 1024]                512,000\n",
            "|    └─SumAggregation: 2-2               [-1, 1024]                --\n",
            "├─GATConv: 1-2                           [-1, 1024]                --\n",
            "|    └─Linear: 2-3                       [-1, 3072]                3,145,728\n",
            "|    └─SumAggregation: 2-4               [-1, 3, 1024]             --\n",
            "├─GCNConv: 1-3                           [-1, 1024]                --\n",
            "|    └─Linear: 2-5                       [-1, 1024]                1,048,576\n",
            "|    └─SumAggregation: 2-6               [-1, 1024]                --\n",
            "├─Linear: 1-4                            [-1, 3]                   3,075\n",
            "==========================================================================================\n",
            "Total params: 4,709,379\n",
            "Trainable params: 4,709,379\n",
            "Non-trainable params: 0\n",
            "Total mult-adds (M): 9.42\n",
            "==========================================================================================\n",
            "Input size (MB): 38.28\n",
            "Forward/backward pass size (MB): 0.04\n",
            "Params size (MB): 17.96\n",
            "Estimated Total Size (MB): 56.29\n",
            "==========================================================================================\n"
          ]
        }
      ],
      "source": [
        "model = Convolucional_Softmax(\n",
        "    dataset.num_node_features,\n",
        "    1024,\n",
        "    dataset.num_classes\n",
        ")\n",
        "\n",
        "summary(model, (data.x, data.edge_index));"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 0: Loss 1.0963342189788818\n",
            "Epoch 10: Loss 1.0370769500732422\n",
            "Epoch 20: Loss 0.5303160548210144\n",
            "Epoch 30: Loss 0.3833645284175873\n",
            "Epoch 40: Loss 0.3225124180316925\n",
            "Epoch 50: Loss 0.2930957078933716\n",
            "Epoch 60: Loss 0.2646530568599701\n",
            "Epoch 70: Loss 0.2682093679904938\n",
            "Epoch 80: Loss 0.24866603314876556\n",
            "Epoch 90: Loss 0.2603994607925415\n",
            "Epoch 100: Loss 0.20964859426021576\n",
            "Epoch 110: Loss 0.21328772604465485\n",
            "Epoch 120: Loss 0.1959710717201233\n",
            "Epoch 130: Loss 0.16626381874084473\n",
            "Epoch 140: Loss 0.3544591963291168\n",
            "Epoch 150: Loss 0.22841808199882507\n",
            "Epoch 160: Loss 0.17901961505413055\n",
            "Epoch 170: Loss 0.1616029292345047\n",
            "Epoch 180: Loss 0.1390870362520218\n",
            "Epoch 190: Loss 0.23041704297065735\n",
            "Epoch 200: Loss 0.15507656335830688\n",
            "Epoch 210: Loss 0.1329539269208908\n",
            "Epoch 220: Loss 0.11308877170085907\n",
            "Epoch 230: Loss 0.33990639448165894\n",
            "Epoch 240: Loss 0.19866010546684265\n",
            "Epoch 250: Loss 0.15989623963832855\n",
            "Epoch 260: Loss 0.13364683091640472\n",
            "Epoch 270: Loss 0.1159772202372551\n",
            "Epoch 280: Loss 0.18424971401691437\n",
            "Epoch 290: Loss 0.18276438117027283\n",
            "Epoch 300: Loss 0.11740262806415558\n",
            "Epoch 310: Loss 0.10483395308256149\n",
            "Epoch 320: Loss 0.09113702178001404\n",
            "Epoch 330: Loss 0.09382230043411255\n",
            "Epoch 340: Loss 0.46940040588378906\n",
            "Epoch 350: Loss 0.20750868320465088\n",
            "Epoch 360: Loss 0.17029963433742523\n",
            "Epoch 370: Loss 0.14372166991233826\n",
            "Epoch 380: Loss 0.12593214213848114\n",
            "Epoch 390: Loss 0.10863175243139267\n",
            "Epoch 400: Loss 0.10410398989915848\n",
            "Epoch 410: Loss 0.09037487953901291\n",
            "Epoch 420: Loss 0.0960475280880928\n",
            "Epoch 430: Loss 0.0940752625465393\n",
            "Epoch 440: Loss 0.08311551809310913\n",
            "Epoch 450: Loss 0.08446233719587326\n",
            "Epoch 460: Loss 0.07943953573703766\n",
            "Epoch 470: Loss 0.0686185210943222\n",
            "Epoch 480: Loss 0.13112473487854004\n",
            "Epoch 490: Loss 0.21495574712753296\n",
            "Epoch 500: Loss 0.12575499713420868\n",
            "Epoch 510: Loss 0.09720557928085327\n",
            "Epoch 520: Loss 0.08437777310609818\n",
            "Epoch 530: Loss 0.07728780061006546\n",
            "Epoch 540: Loss 0.07161845266819\n",
            "Epoch 550: Loss 0.06437378376722336\n",
            "Epoch 560: Loss 0.06021780148148537\n",
            "Epoch 570: Loss 0.08304613083600998\n",
            "Epoch 580: Loss 0.12839655578136444\n",
            "Epoch 590: Loss 0.09546047449111938\n",
            "Epoch 600: Loss 0.07769012451171875\n",
            "Epoch 610: Loss 0.19694358110427856\n",
            "Epoch 620: Loss 0.10041368752717972\n",
            "Epoch 630: Loss 0.07838353514671326\n",
            "Epoch 640: Loss 0.0845232903957367\n",
            "Epoch 650: Loss 0.06597109884023666\n",
            "Epoch 660: Loss 0.06511054933071136\n",
            "Epoch 670: Loss 0.05991838872432709\n",
            "Epoch 680: Loss 0.05470273643732071\n",
            "Epoch 690: Loss 0.05253142863512039\n",
            "Epoch 700: Loss 0.051468685269355774\n",
            "Epoch 710: Loss 0.0651632621884346\n",
            "Epoch 720: Loss 0.0595608651638031\n",
            "Epoch 730: Loss 0.05046297609806061\n",
            "Epoch 740: Loss 0.0466606542468071\n",
            "Epoch 750: Loss 0.40057697892189026\n",
            "Epoch 760: Loss 0.45843103528022766\n",
            "Epoch 770: Loss 0.29291731119155884\n",
            "Epoch 780: Loss 0.2548398971557617\n",
            "Epoch 790: Loss 0.22940967977046967\n",
            "Epoch 800: Loss 0.1996852159500122\n",
            "Epoch 810: Loss 0.197350412607193\n",
            "Epoch 820: Loss 0.1776839792728424\n",
            "Epoch 830: Loss 0.16080528497695923\n",
            "Epoch 840: Loss 0.14494113624095917\n",
            "Epoch 850: Loss 0.18026980757713318\n",
            "Epoch 860: Loss 0.13981115818023682\n",
            "Epoch 870: Loss 0.135004922747612\n",
            "Epoch 880: Loss 0.11595100909471512\n",
            "Epoch 890: Loss 0.10631854832172394\n",
            "Epoch 900: Loss 0.11033616960048676\n",
            "Epoch 910: Loss 0.094416044652462\n",
            "Epoch 920: Loss 0.08927647769451141\n",
            "Epoch 930: Loss 0.08835200220346451\n",
            "Epoch 940: Loss 0.08258816599845886\n",
            "Epoch 950: Loss 0.07617662101984024\n",
            "Epoch 960: Loss 0.1557476669549942\n",
            "Epoch 970: Loss 0.09367741644382477\n",
            "Epoch 980: Loss 0.22883597016334534\n",
            "Epoch 990: Loss 0.1429581642150879\n",
            "\n",
            "\n",
            "MODEL VALIDATION:\n",
            "\n",
            "Validation F1 score: 0.8771830985915493\n",
            "\n",
            "\n",
            "MODEL TEST:\n",
            "\n",
            "Test F1 score: 0.8894523326572008\n"
          ]
        }
      ],
      "source": [
        "train_model(model, \"Convolucional Softmax\", data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "kJ5nWyjofWwT"
      },
      "outputs": [],
      "source": [
        "class Convolucional_Droput(nn.Module):\n",
        "    def __init__(self, in_channels, hidden_channels, out_channels, dropout_rate=0.5):\n",
        "        super(Convolucional_Droput, self).__init__()\n",
        "\n",
        "        # Capas de GNN\n",
        "        self.gcn1 = GCNConv(in_channels, hidden_channels)\n",
        "        self.gat = GATConv(hidden_channels, hidden_channels, heads=3, concat=False)\n",
        "        self.gcn2 = GCNConv(hidden_channels, hidden_channels)\n",
        "\n",
        "        # Capas densas finales\n",
        "        self.fc1 = nn.Linear(hidden_channels, hidden_channels // 2)\n",
        "        self.fc2 = nn.Linear(hidden_channels // 2, out_channels)\n",
        "\n",
        "        # Dropout rate\n",
        "        self.dropout_rate = dropout_rate\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        # Primera capa GCN\n",
        "        x = F.relu(self.gcn1(x, edge_index))\n",
        "        x = F.dropout(x, p=self.dropout_rate, training=self.training)\n",
        "\n",
        "        # Atención con GAT\n",
        "        x = F.relu(self.gat(x, edge_index))\n",
        "        x = F.dropout(x, p=self.dropout_rate, training=self.training)\n",
        "\n",
        "        # Segunda capa GCN\n",
        "        x = F.relu(self.gcn2(x, edge_index))\n",
        "        x = F.dropout(x, p=self.dropout_rate, training=self.training)\n",
        "\n",
        "        # Capas densas finales\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.dropout(x, p=self.dropout_rate, training=self.training)\n",
        "        x = self.fc2(x)\n",
        "\n",
        "        return F.log_softmax(x, dim=1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "TIZh0RC2fX0V"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==========================================================================================\n",
            "Layer (type:depth-idx)                   Output Shape              Param #\n",
            "==========================================================================================\n",
            "├─GCNConv: 1-1                           [-1, 1024]                --\n",
            "|    └─Linear: 2-1                       [-1, 1024]                512,000\n",
            "|    └─SumAggregation: 2-2               [-1, 1024]                --\n",
            "├─GATConv: 1-2                           [-1, 1024]                --\n",
            "|    └─Linear: 2-3                       [-1, 3072]                3,145,728\n",
            "|    └─SumAggregation: 2-4               [-1, 3, 1024]             --\n",
            "├─GCNConv: 1-3                           [-1, 1024]                --\n",
            "|    └─Linear: 2-5                       [-1, 1024]                1,048,576\n",
            "|    └─SumAggregation: 2-6               [-1, 1024]                --\n",
            "├─Linear: 1-4                            [-1, 512]                 524,800\n",
            "├─Linear: 1-5                            [-1, 3]                   1,539\n",
            "==========================================================================================\n",
            "Total params: 5,232,643\n",
            "Trainable params: 5,232,643\n",
            "Non-trainable params: 0\n",
            "Total mult-adds (M): 9.94\n",
            "==========================================================================================\n",
            "Input size (MB): 38.28\n",
            "Forward/backward pass size (MB): 0.04\n",
            "Params size (MB): 19.96\n",
            "Estimated Total Size (MB): 58.29\n",
            "==========================================================================================\n"
          ]
        }
      ],
      "source": [
        "model = Convolucional_Droput(\n",
        "    dataset.num_node_features,\n",
        "    1024,\n",
        "    dataset.num_classes\n",
        ")\n",
        "\n",
        "summary(model, (data.x, data.edge_index));"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 0: Loss 1.1075527667999268\n",
            "Epoch 10: Loss 1.0618896484375\n",
            "Epoch 20: Loss 0.9239147901535034\n",
            "Epoch 30: Loss 0.767058253288269\n",
            "Epoch 40: Loss 0.7035830616950989\n",
            "Epoch 50: Loss 0.6331450343132019\n",
            "Epoch 60: Loss 0.4169538915157318\n",
            "Epoch 70: Loss 0.3492259681224823\n",
            "Epoch 80: Loss 0.30021026730537415\n",
            "Epoch 90: Loss 0.2820627987384796\n",
            "Epoch 100: Loss 0.2704602777957916\n",
            "Epoch 110: Loss 0.24472366273403168\n",
            "Epoch 120: Loss 0.246921569108963\n",
            "Epoch 130: Loss 0.23847393691539764\n",
            "Epoch 140: Loss 0.2238328605890274\n",
            "Epoch 150: Loss 0.21691839396953583\n",
            "Epoch 160: Loss 0.20535914599895477\n",
            "Epoch 170: Loss 0.22637556493282318\n",
            "Epoch 180: Loss 0.205704003572464\n",
            "Epoch 190: Loss 0.19206950068473816\n",
            "Epoch 200: Loss 0.20894479751586914\n",
            "Epoch 210: Loss 0.20064549148082733\n",
            "Epoch 220: Loss 0.1920214146375656\n",
            "Epoch 230: Loss 0.20008499920368195\n",
            "Epoch 240: Loss 0.18029513955116272\n",
            "Epoch 250: Loss 0.1744617223739624\n",
            "Epoch 260: Loss 0.2192462682723999\n",
            "Epoch 270: Loss 0.2219155877828598\n",
            "Epoch 280: Loss 0.18529962003231049\n",
            "Epoch 290: Loss 0.6401337385177612\n",
            "Epoch 300: Loss 0.27623727917671204\n",
            "Epoch 310: Loss 0.20875540375709534\n",
            "Epoch 320: Loss 0.18462714552879333\n",
            "Epoch 330: Loss 0.16935454308986664\n",
            "Epoch 340: Loss 0.16708147525787354\n",
            "Epoch 350: Loss 0.163740873336792\n",
            "Epoch 360: Loss 0.17065049707889557\n",
            "Epoch 370: Loss 0.16506549715995789\n",
            "Epoch 380: Loss 0.14943961799144745\n",
            "Epoch 390: Loss 0.16519872844219208\n",
            "Epoch 400: Loss 0.1577550619840622\n",
            "Epoch 410: Loss 0.16594761610031128\n",
            "Epoch 420: Loss 0.1683531552553177\n",
            "Epoch 430: Loss 0.14306044578552246\n",
            "Epoch 440: Loss 0.25341182947158813\n",
            "Epoch 450: Loss 0.2160523235797882\n",
            "Epoch 460: Loss 0.1873815804719925\n",
            "Epoch 470: Loss 0.1719437837600708\n",
            "Epoch 480: Loss 0.1740693897008896\n",
            "Epoch 490: Loss 0.2281254380941391\n",
            "Epoch 500: Loss 0.27567732334136963\n",
            "Epoch 510: Loss 0.17574580013751984\n",
            "Epoch 520: Loss 0.17477568984031677\n",
            "Epoch 530: Loss 0.1526656299829483\n",
            "Epoch 540: Loss 0.16171567142009735\n",
            "Epoch 550: Loss 0.14823798835277557\n",
            "Epoch 560: Loss 0.14280562102794647\n",
            "Epoch 570: Loss 0.13986358046531677\n",
            "Epoch 580: Loss 0.14039237797260284\n",
            "Epoch 590: Loss 0.14811602234840393\n",
            "Epoch 600: Loss 0.139581561088562\n",
            "Epoch 610: Loss 0.24597777426242828\n",
            "Epoch 620: Loss 0.17089475691318512\n",
            "Epoch 630: Loss 0.1970893144607544\n",
            "Epoch 640: Loss 0.1929791420698166\n",
            "Epoch 650: Loss 0.14552204310894012\n",
            "Epoch 660: Loss 0.1402716189622879\n",
            "Epoch 670: Loss 0.13794434070587158\n",
            "Epoch 680: Loss 0.13310027122497559\n",
            "Epoch 690: Loss 0.26355618238449097\n",
            "Epoch 700: Loss 0.2613990604877472\n",
            "Epoch 710: Loss 0.1807069629430771\n",
            "Epoch 720: Loss 0.17302390933036804\n",
            "Epoch 730: Loss 0.1526525467634201\n",
            "Epoch 740: Loss 0.5249544382095337\n",
            "Epoch 750: Loss 0.38375380635261536\n",
            "Epoch 760: Loss 0.3253682553768158\n",
            "Epoch 770: Loss 0.23268072307109833\n",
            "Epoch 780: Loss 0.2056678831577301\n",
            "Epoch 790: Loss 0.19393500685691833\n",
            "Epoch 800: Loss 0.18141616880893707\n",
            "Epoch 810: Loss 0.18001700937747955\n",
            "Epoch 820: Loss 0.16683898866176605\n",
            "Epoch 830: Loss 0.20021861791610718\n",
            "Epoch 840: Loss 0.15631769597530365\n",
            "Epoch 850: Loss 0.15623806416988373\n",
            "Epoch 860: Loss 0.15617094933986664\n",
            "Epoch 870: Loss 0.14994455873966217\n",
            "Epoch 880: Loss 0.15131840109825134\n",
            "Epoch 890: Loss 0.1652408093214035\n",
            "Epoch 900: Loss 0.15753695368766785\n",
            "Epoch 910: Loss 0.7114661335945129\n",
            "Epoch 920: Loss 0.44619306921958923\n",
            "Epoch 930: Loss 0.3523912727832794\n",
            "Epoch 940: Loss 0.29878294467926025\n",
            "Epoch 950: Loss 0.286936491727829\n",
            "Epoch 960: Loss 0.2548159658908844\n",
            "Epoch 970: Loss 0.24025775492191315\n",
            "Epoch 980: Loss 0.23678548634052277\n",
            "Epoch 990: Loss 0.2207953929901123\n",
            "\n",
            "\n",
            "MODEL VALIDATION:\n",
            "\n",
            "Validation F1 score: 0.8749295774647887\n",
            "\n",
            "\n",
            "MODEL TEST:\n",
            "\n",
            "Test F1 score: 0.896551724137931\n"
          ]
        }
      ],
      "source": [
        "train_model(model, \"Convolucional Dropout\", data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Aproximación IV - Graph Sage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "n4I4VyLoih8I"
      },
      "outputs": [],
      "source": [
        "class GraphSAGEModel(torch.nn.Module):\n",
        "    def __init__(self, in_channels, hidden_channels, out_channels, dropout_rate=0.5):\n",
        "        super(GraphSAGEModel, self).__init__()\n",
        "\n",
        "        # Capas convolucionales\n",
        "        self.conv1 = SAGEConv(in_channels, hidden_channels)\n",
        "        self.conv2 = SAGEConv(hidden_channels, hidden_channels)\n",
        "        self.conv3 = SAGEConv(hidden_channels, hidden_channels)\n",
        "        self.conv4 = SAGEConv(hidden_channels, hidden_channels)\n",
        "\n",
        "        # Capas densas\n",
        "        self.fc1 = torch.nn.Linear(hidden_channels, hidden_channels // 2)\n",
        "        self.fc2 = torch.nn.Linear(hidden_channels // 2, hidden_channels // 4)\n",
        "        self.fc3 = torch.nn.Linear(hidden_channels // 4, out_channels)\n",
        "\n",
        "        # Dropout rate\n",
        "        self.dropout_rate = dropout_rate\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        # Capas convolucionales\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = F.relu(x)\n",
        "        x = self.conv2(x, edge_index)\n",
        "        x = F.relu(x)\n",
        "        x = self.conv3(x, edge_index)\n",
        "        x = F.relu(x)\n",
        "        x = self.conv4(x, edge_index)\n",
        "\n",
        "        # Capas densas\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.dropout(x, p=self.dropout_rate, training=self.training)\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = F.dropout(x, p=self.dropout_rate, training=self.training)\n",
        "        x = F.relu(self.fc3(x))\n",
        "\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "T6JftgCsikHu"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==========================================================================================\n",
            "Layer (type:depth-idx)                   Output Shape              Param #\n",
            "==========================================================================================\n",
            "├─SAGEConv: 1-1                          [-1, 64]                  --\n",
            "|    └─MeanAggregation: 2-1              [-1, 500]                 --\n",
            "|    └─Linear: 2-2                       [-1, 64]                  32,064\n",
            "|    └─Linear: 2-3                       [-1, 64]                  32,000\n",
            "├─SAGEConv: 1-2                          [-1, 64]                  --\n",
            "|    └─MeanAggregation: 2-4              [-1, 64]                  --\n",
            "|    └─Linear: 2-5                       [-1, 64]                  4,160\n",
            "|    └─Linear: 2-6                       [-1, 64]                  4,096\n",
            "├─SAGEConv: 1-3                          [-1, 64]                  --\n",
            "|    └─MeanAggregation: 2-7              [-1, 64]                  --\n",
            "|    └─Linear: 2-8                       [-1, 64]                  4,160\n",
            "|    └─Linear: 2-9                       [-1, 64]                  4,096\n",
            "├─SAGEConv: 1-4                          [-1, 64]                  --\n",
            "|    └─MeanAggregation: 2-10             [-1, 64]                  --\n",
            "|    └─Linear: 2-11                      [-1, 64]                  4,160\n",
            "|    └─Linear: 2-12                      [-1, 64]                  4,096\n",
            "├─Linear: 1-5                            [-1, 32]                  2,080\n",
            "├─Linear: 1-6                            [-1, 16]                  528\n",
            "├─Linear: 1-7                            [-1, 3]                   51\n",
            "==========================================================================================\n",
            "Total params: 91,491\n",
            "Trainable params: 91,491\n",
            "Non-trainable params: 0\n",
            "Total mult-adds (M): 0.18\n",
            "==========================================================================================\n",
            "Input size (MB): 38.28\n",
            "Forward/backward pass size (MB): 0.00\n",
            "Params size (MB): 0.35\n",
            "Estimated Total Size (MB): 38.64\n",
            "==========================================================================================\n"
          ]
        }
      ],
      "source": [
        "model = GraphSAGEModel(\n",
        "    dataset.num_node_features,\n",
        "    64,\n",
        "    dataset.num_classes\n",
        ")\n",
        "\n",
        "summary(model, (data.x, data.edge_index));"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 0: Loss 1.085205316543579\n",
            "Epoch 10: Loss 0.9382565021514893\n",
            "Epoch 20: Loss 0.7641995549201965\n",
            "Epoch 30: Loss 0.5673186779022217\n",
            "Epoch 40: Loss 0.43662214279174805\n",
            "Epoch 50: Loss 0.34925469756126404\n",
            "Epoch 60: Loss 0.32298359274864197\n",
            "Epoch 70: Loss 0.265854150056839\n",
            "Epoch 80: Loss 0.20395880937576294\n",
            "Epoch 90: Loss 0.19447343051433563\n",
            "Epoch 100: Loss 0.2540947496891022\n",
            "Epoch 110: Loss 0.18621952831745148\n",
            "Epoch 120: Loss 0.14230160415172577\n",
            "Epoch 130: Loss 0.11209769546985626\n",
            "Epoch 140: Loss 0.09838292747735977\n",
            "Epoch 150: Loss 0.0897815003991127\n",
            "Epoch 160: Loss 0.3152233064174652\n",
            "Epoch 170: Loss 0.44540533423423767\n",
            "Epoch 180: Loss 0.3675389289855957\n",
            "Epoch 190: Loss 0.2773006856441498\n",
            "Epoch 200: Loss 0.19345135986804962\n",
            "Epoch 210: Loss 0.1979335993528366\n",
            "Epoch 220: Loss 0.23118546605110168\n",
            "Epoch 230: Loss 0.14259515702724457\n",
            "Epoch 240: Loss 0.11866258084774017\n",
            "Epoch 250: Loss 0.10445050150156021\n",
            "Epoch 260: Loss 0.09693131595849991\n",
            "Epoch 270: Loss 0.09560416638851166\n",
            "Epoch 280: Loss 0.093114472925663\n",
            "Epoch 290: Loss 0.09001606702804565\n",
            "Epoch 300: Loss 0.08491373062133789\n",
            "Epoch 310: Loss 0.08639486134052277\n",
            "Epoch 320: Loss 0.07838800549507141\n",
            "Epoch 330: Loss 0.34880688786506653\n",
            "Epoch 340: Loss 0.1489230990409851\n",
            "Epoch 350: Loss 0.11855916678905487\n",
            "Epoch 360: Loss 0.10042157769203186\n",
            "Epoch 370: Loss 0.21424591541290283\n",
            "Epoch 380: Loss 0.1135764941573143\n",
            "Epoch 390: Loss 0.09257248044013977\n",
            "Epoch 400: Loss 0.08367481082677841\n",
            "Epoch 410: Loss 0.07591550797224045\n",
            "Epoch 420: Loss 0.07317697256803513\n",
            "Epoch 430: Loss 0.06983191519975662\n",
            "Epoch 440: Loss 0.27016645669937134\n",
            "Epoch 450: Loss 0.15856802463531494\n",
            "Epoch 460: Loss 0.10696401447057724\n",
            "Epoch 470: Loss 0.08500012010335922\n",
            "Epoch 480: Loss 0.0739070326089859\n",
            "Epoch 490: Loss 0.06651531159877777\n",
            "Epoch 500: Loss 0.06748811900615692\n",
            "Epoch 510: Loss 0.06375455111265182\n",
            "Epoch 520: Loss 0.06181579828262329\n",
            "Epoch 530: Loss 0.06195773929357529\n",
            "Epoch 540: Loss 0.060344111174345016\n",
            "Epoch 550: Loss 0.05705578252673149\n",
            "Epoch 560: Loss 0.0536237433552742\n",
            "Epoch 570: Loss 0.050548773258924484\n",
            "Epoch 580: Loss 0.054033707827329636\n",
            "Epoch 590: Loss 0.04938946291804314\n",
            "Epoch 600: Loss 0.4567491114139557\n",
            "Epoch 610: Loss 1.0776413679122925\n",
            "Epoch 620: Loss 0.766467809677124\n",
            "Epoch 630: Loss 0.587673544883728\n",
            "Epoch 640: Loss 0.5074252486228943\n",
            "Epoch 650: Loss 0.44220346212387085\n",
            "Epoch 660: Loss 0.3764345943927765\n",
            "Epoch 670: Loss 0.684212327003479\n",
            "Epoch 680: Loss 0.4395601451396942\n",
            "Epoch 690: Loss 0.35639557242393494\n",
            "Epoch 700: Loss 0.30046629905700684\n",
            "Epoch 710: Loss 0.2539606988430023\n",
            "Epoch 720: Loss 0.22280822694301605\n",
            "Epoch 730: Loss 0.23903916776180267\n",
            "Epoch 740: Loss 0.2633504271507263\n",
            "Epoch 750: Loss 0.2130076140165329\n",
            "Epoch 760: Loss 0.1907356232404709\n",
            "Epoch 770: Loss 0.17724716663360596\n",
            "Epoch 780: Loss 0.17397919297218323\n",
            "Epoch 790: Loss 0.16662690043449402\n",
            "Epoch 800: Loss 0.16336511075496674\n",
            "Epoch 810: Loss 0.16187766194343567\n",
            "Epoch 820: Loss 0.15777920186519623\n",
            "Epoch 830: Loss 0.1526060849428177\n",
            "Epoch 840: Loss 0.14827114343643188\n",
            "Epoch 850: Loss 0.15378768742084503\n",
            "Epoch 860: Loss 0.14612694084644318\n",
            "Epoch 870: Loss 0.14644864201545715\n",
            "Epoch 880: Loss 0.3340388536453247\n",
            "Epoch 890: Loss 0.21241870522499084\n",
            "Epoch 900: Loss 0.16179531812667847\n",
            "Epoch 910: Loss 0.14211516082286835\n",
            "Epoch 920: Loss 0.13275158405303955\n",
            "Epoch 930: Loss 0.12776483595371246\n",
            "Epoch 940: Loss 0.1272725760936737\n",
            "Epoch 950: Loss 0.11991386115550995\n",
            "Epoch 960: Loss 0.1169200986623764\n",
            "Epoch 970: Loss 0.11657410115003586\n",
            "Epoch 980: Loss 0.11008270829916\n",
            "Epoch 990: Loss 0.10926468670368195\n",
            "\n",
            "\n",
            "MODEL VALIDATION:\n",
            "\n",
            "Validation F1 score: 0.8743661971830986\n",
            "\n",
            "\n",
            "MODEL TEST:\n",
            "\n",
            "Test F1 score: 0.890973630831643\n"
          ]
        }
      ],
      "source": [
        "train_model(model, \"Graph SAGE\", data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Comparación entre modelos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Separate validation and test scores\n",
        "val_scores = [scores[0] for scores in f1_by_model.values()]\n",
        "test_scores = [scores[1] for scores in f1_by_model.values()]\n",
        "\n",
        "# Define colors for the bars\n",
        "colors_val = ['grey' if f1 != max(val_scores) else 'red' for f1 in val_scores]\n",
        "colors_test = ['grey' if f1 != max(test_scores) else 'red' for f1 in test_scores]\n",
        "\n",
        "# Create subplots\n",
        "fig, ax = plt.subplots()\n",
        "\n",
        "# Define bar width and positions\n",
        "bar_width = 0.35\n",
        "index = np.arange(len(f1_by_model))\n",
        "\n",
        "# Plot validation scores\n",
        "bars_val = ax.bar(index, val_scores, bar_width, color=colors_val, label='Validation')\n",
        "\n",
        "# Plot test scores\n",
        "bars_test = ax.bar(index + bar_width, test_scores, bar_width, color=colors_test, label='Test', alpha=0.7)\n",
        "\n",
        "# Add value labels inside each bar\n",
        "for bar in bars_val + bars_test:\n",
        "    yval = bar.get_height()\n",
        "    ax.text(bar.get_x() + bar.get_width() / 2, yval * 0.9, round(yval, 4), ha='center', va='center', rotation='vertical', color='white')\n",
        "\n",
        "# Rotate x-axis labels for better readability\n",
        "plt.xticks(index + bar_width / 2, f1_by_model.keys(), rotation=90)\n",
        "\n",
        "# Add title and legend\n",
        "plt.title(\"Validation and Test F1 score by model\")\n",
        "plt.legend()\n",
        "\n",
        "# Show plot\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XagHI5QV1iAE"
      },
      "source": [
        "# Generar solución para el torneo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "PgPBu9b11mf0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 0: Loss 1.1063209772109985\n",
            "Epoch 10: Loss 1.0844943523406982\n",
            "Epoch 20: Loss 1.035891056060791\n",
            "Epoch 30: Loss 1.0347788333892822\n",
            "Epoch 40: Loss 0.7790254354476929\n",
            "Epoch 50: Loss 0.7175074815750122\n",
            "Epoch 60: Loss 0.7230209708213806\n",
            "Epoch 70: Loss 0.5873377323150635\n",
            "Epoch 80: Loss 0.43800845742225647\n",
            "Epoch 90: Loss 0.35876402258872986\n",
            "Epoch 100: Loss 0.35935670137405396\n",
            "Epoch 110: Loss 0.31475433707237244\n",
            "Epoch 120: Loss 0.30180543661117554\n",
            "Epoch 130: Loss 0.29872146248817444\n",
            "Epoch 140: Loss 0.2779402732849121\n",
            "Epoch 150: Loss 0.3096025884151459\n",
            "Epoch 160: Loss 0.27280193567276\n",
            "Epoch 170: Loss 0.2569926381111145\n",
            "Epoch 180: Loss 0.24561570584774017\n",
            "Epoch 190: Loss 0.264024943113327\n",
            "Epoch 200: Loss 0.24509891867637634\n",
            "Epoch 210: Loss 0.22429855167865753\n",
            "Epoch 220: Loss 0.38868293166160583\n",
            "Epoch 230: Loss 0.2430698722600937\n",
            "Epoch 240: Loss 0.2224734127521515\n",
            "Epoch 250: Loss 0.22249281406402588\n",
            "Epoch 260: Loss 0.2123962789773941\n",
            "Epoch 270: Loss 0.2006840854883194\n",
            "Epoch 280: Loss 0.25778263807296753\n",
            "Epoch 290: Loss 0.23208527266979218\n",
            "Epoch 300: Loss 0.1994558870792389\n",
            "Epoch 310: Loss 0.18433156609535217\n",
            "Epoch 320: Loss 0.19540371000766754\n",
            "Epoch 330: Loss 0.17969992756843567\n",
            "Epoch 340: Loss 0.33287110924720764\n",
            "Epoch 350: Loss 0.2167302966117859\n",
            "Epoch 360: Loss 0.18753290176391602\n",
            "Epoch 370: Loss 0.17206935584545135\n",
            "Epoch 380: Loss 0.17403057217597961\n",
            "Epoch 390: Loss 0.16390570998191833\n",
            "Epoch 400: Loss 0.30235597491264343\n",
            "Epoch 410: Loss 0.2355145364999771\n",
            "Epoch 420: Loss 0.18409980833530426\n",
            "Epoch 430: Loss 0.18415185809135437\n",
            "Epoch 440: Loss 0.1838475912809372\n",
            "Epoch 450: Loss 0.15793900191783905\n",
            "Epoch 460: Loss 0.15749360620975494\n",
            "Epoch 470: Loss 0.15460312366485596\n",
            "Epoch 480: Loss 0.557508111000061\n",
            "Epoch 490: Loss 0.34409773349761963\n",
            "Epoch 500: Loss 0.23961758613586426\n",
            "Epoch 510: Loss 0.20635820925235748\n",
            "Epoch 520: Loss 0.17921796441078186\n",
            "Epoch 530: Loss 0.16733461618423462\n",
            "Epoch 540: Loss 0.5804203748703003\n",
            "Epoch 550: Loss 0.2821407914161682\n",
            "Epoch 560: Loss 0.2217506617307663\n",
            "Epoch 570: Loss 0.21840864419937134\n",
            "Epoch 580: Loss 0.17669829726219177\n",
            "Epoch 590: Loss 0.1703576296567917\n",
            "Epoch 600: Loss 0.24227288365364075\n",
            "Epoch 610: Loss 0.23567216098308563\n",
            "Epoch 620: Loss 0.18262892961502075\n",
            "Epoch 630: Loss 0.1574932485818863\n",
            "Epoch 640: Loss 0.15407052636146545\n",
            "Epoch 650: Loss 0.15199244022369385\n",
            "Epoch 660: Loss 0.14593636989593506\n",
            "Epoch 670: Loss 0.17028680443763733\n",
            "Epoch 680: Loss 0.14539361000061035\n",
            "Epoch 690: Loss 0.13878373801708221\n",
            "Epoch 700: Loss 0.1399887204170227\n",
            "Epoch 710: Loss 0.13104978203773499\n",
            "Epoch 720: Loss 0.15285930037498474\n",
            "Epoch 730: Loss 0.13394343852996826\n",
            "Epoch 740: Loss 0.7701936364173889\n",
            "Epoch 750: Loss 0.6001585125923157\n",
            "Epoch 760: Loss 0.46583321690559387\n",
            "Epoch 770: Loss 0.35258063673973083\n",
            "Epoch 780: Loss 0.30074140429496765\n",
            "Epoch 790: Loss 0.25540095567703247\n",
            "Epoch 800: Loss 0.2287481725215912\n",
            "Epoch 810: Loss 0.21208709478378296\n",
            "Epoch 820: Loss 0.19783927500247955\n",
            "Epoch 830: Loss 0.1841997653245926\n",
            "Epoch 840: Loss 0.17919811606407166\n",
            "Epoch 850: Loss 0.18874846398830414\n",
            "Epoch 860: Loss 0.17115874588489532\n",
            "Epoch 870: Loss 0.1713489592075348\n",
            "Epoch 880: Loss 0.16971585154533386\n",
            "Epoch 890: Loss 0.15976744890213013\n",
            "Epoch 900: Loss 0.16263945400714874\n",
            "Epoch 910: Loss 0.20473934710025787\n",
            "Epoch 920: Loss 0.1701771765947342\n",
            "Epoch 930: Loss 0.15823540091514587\n",
            "Epoch 940: Loss 0.16140933334827423\n",
            "Epoch 950: Loss 0.16014845669269562\n",
            "Epoch 960: Loss 0.149664044380188\n",
            "Epoch 970: Loss 0.15271392464637756\n",
            "Epoch 980: Loss 0.15464715659618378\n",
            "Epoch 990: Loss 0.5424678921699524\n",
            "\n",
            "\n",
            "MODEL VALIDATION:\n",
            "\n",
            "Validation F1 score: 0.8636619718309859\n",
            "\n",
            "\n",
            "MODEL TEST:\n",
            "\n",
            "Test F1 score: 0.8788032454361054\n"
          ]
        }
      ],
      "source": [
        "model = Convolucional_Droput(\n",
        "    dataset.num_node_features,\n",
        "    1024,\n",
        "    dataset.num_classes\n",
        ")\n",
        "\n",
        "train_model(model, \"Convolucional Dropout\", data)\n",
        "\n",
        "dataset.create_test_json(model, 'pred_labels.json', device='cuda')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
