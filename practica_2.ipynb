{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MHRJ5fOq0XlQ"
      },
      "source": [
        "# Importar dependencias"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "import torch\n",
        "import os.path as osp\n",
        "from torch_geometric.data import InMemoryDataset, download_url\n",
        "import torch\n",
        "from torch.nn import CrossEntropyLoss\n",
        "from torch.optim import Adam\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix, f1_score\n",
        "from torch_geometric.nn import MLP\n",
        "from torch.nn import Module\n",
        "from torch_geometric.nn import GCN, MLP\n",
        "from torch.nn import Module\n",
        "from torch_geometric.nn import GIN, MLP\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import GCNConv, GATConv\n",
        "from torchsummary import summary\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oywdRiO90dBy"
      },
      "source": [
        "# Cargar el dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.cuda.is_available()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "63VQAhc-zn8d"
      },
      "outputs": [],
      "source": [
        "class TournamentDataset(InMemoryDataset):\n",
        "\n",
        "    TORUNAMENT_URL = 'https://drive.upm.es/s/mnsESjBucKUKsEg/download'\n",
        "\n",
        "    def __init__(self, root, transform=None, pre_transform=None, pre_filter=None):\n",
        "        super().__init__(root, transform, pre_transform, pre_filter)\n",
        "        self.load(self.processed_paths[0])\n",
        "\n",
        "    @property\n",
        "    def raw_file_names(self):\n",
        "        return ['tournament.pt']\n",
        "\n",
        "    @property\n",
        "    def processed_file_names(self):\n",
        "        return ['tournament.pt']\n",
        "\n",
        "    @property\n",
        "    def num_classes(self):\n",
        "        return 3\n",
        "\n",
        "    @property\n",
        "    def num_features(self):\n",
        "        return 500\n",
        "\n",
        "    def download(self):\n",
        "        download_url(self.TORUNAMENT_URL, self.raw_dir, filename='tournament.pt')\n",
        "\n",
        "    def process(self):\n",
        "        data_list = [torch.load(osp.join(self.raw_dir, 'tournament.pt'))]\n",
        "\n",
        "        if self.pre_filter is not None:\n",
        "            data_list = [data for data in data_list if self.pre_filter(data)]\n",
        "\n",
        "        if self.pre_transform is not None:\n",
        "            data_list = [self.pre_transform(data) for data in data_list]\n",
        "\n",
        "        self.save(data_list, self.processed_paths[0])\n",
        "\n",
        "    def create_test_json(self, model, file_path, device=\"cpu\"):\n",
        "        data = self[0]\n",
        "\n",
        "        model = model.to(device)\n",
        "        data = data.to(device)\n",
        "\n",
        "        model.eval()\n",
        "        out = model(data.x, data.edge_index)\n",
        "        y_pred = out[data.test_mask].argmax(dim=1)\n",
        "        nid = data.nid[data.test_mask]\n",
        "\n",
        "        pred = {\n",
        "            'nid': nid.detach().cpu().numpy().tolist(),\n",
        "            'y': y_pred.detach().cpu().numpy().tolist()\n",
        "        }\n",
        "\n",
        "        with open(file_path, 'w') as f:\n",
        "            json.dump(pred, f)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BmhQysdi0B7O",
        "outputId": "d162c7b8-704a-4da8-ff02-540c3a0cc9e3"
      },
      "outputs": [],
      "source": [
        "dataset = TournamentDataset(\"tournament\")\n",
        "data = dataset[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(15970)\n",
            "tensor(1775)\n",
            "tensor(1972)\n"
          ]
        }
      ],
      "source": [
        "print(data.train_mask.sum())\n",
        "print(data.val_mask.sum())\n",
        "print(data.test_mask.sum())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hh4l8P3e0y7G"
      },
      "source": [
        "# Modelos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "f1_by_model = {}\n",
        "\n",
        "def train_model(model, model_name, dataset):\n",
        "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "    model = model.to(device)\n",
        "\n",
        "    optimizer = Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
        "    optm_func = CrossEntropyLoss()\n",
        "\n",
        "    data = dataset.to(device)\n",
        "\n",
        "    model.train()\n",
        "    for epoch in range(1000):\n",
        "        optimizer.zero_grad()\n",
        "        out = model(data.x, data.edge_index)\n",
        "        loss = optm_func(out[data.train_mask], data.y[data.train_mask].argmax(dim=1))\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if epoch % 10 == 0:\n",
        "            print(f\"Epoch {epoch}: Loss {loss.item()}\")\n",
        "\n",
        "    model.eval()\n",
        "    out = model(data.x, data.edge_index)\n",
        "\n",
        "    print(\"\\n\\nMODEL VALIDATION:\\n\")\n",
        "    y_pred = out.argmax(dim=1)[data.val_mask].detach().cpu()\n",
        "    y = data.y.argmax(dim=1)[data.val_mask].detach().cpu()\n",
        "\n",
        "    f1_val = f1_score(y, y_pred, average='micro')\n",
        "    print(f\"Validation F1 score: {f1_val}\")\n",
        "    # sns.heatmap(confusion_matrix(y, y_pred), annot=True, fmt='g', cmap='Blues');\n",
        "\n",
        "    print(\"\\n\\nMODEL TEST:\\n\")\n",
        "    y_pred = out.argmax(dim=1)[data.test_mask].detach().cpu()\n",
        "    y_pred = y_pred.numpy()\n",
        "    y = pd.read_csv('test_labels.csv')['y'].values\n",
        "    y = torch.tensor(y).cpu().numpy()\n",
        "    f1_test = f1_score(y, y_pred, average='micro')\n",
        "    print(f\"Test F1 score: {f1_test}\")\n",
        "\n",
        "    f1_by_model[model_name] = [f1_val, f1_test]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Baseline - MLP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==========================================================================================\n",
            "Layer (type:depth-idx)                   Output Shape              Param #\n",
            "==========================================================================================\n",
            "├─ModuleList: 1                          []                        --\n",
            "|    └─Linear: 2-1                       [-1, 32]                  16,032\n",
            "├─ModuleList: 1                          []                        --\n",
            "|    └─BatchNorm: 2-2                    [-1, 32]                  --\n",
            "|    |    └─BatchNorm1d: 3-1             [-1, 32]                  64\n",
            "├─ReLU: 1-1                              [-1, 32]                  --\n",
            "├─ModuleList: 1                          []                        --\n",
            "|    └─Linear: 2-3                       [-1, 3]                   99\n",
            "==========================================================================================\n",
            "Total params: 16,195\n",
            "Trainable params: 16,195\n",
            "Non-trainable params: 0\n",
            "Total mult-adds (M): 0.02\n",
            "==========================================================================================\n",
            "Input size (MB): 38.28\n",
            "Forward/backward pass size (MB): 0.00\n",
            "Params size (MB): 0.06\n",
            "Estimated Total Size (MB): 38.35\n",
            "==========================================================================================\n"
          ]
        }
      ],
      "source": [
        "model = MLP(\n",
        "    in_channels=dataset.num_node_features,\n",
        "    out_channels=dataset.num_classes,\n",
        "    num_layers=2,\n",
        "    hidden_channels=32\n",
        ")\n",
        "summary(model, (data.x, data.edge_index));"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 0: Loss 1.1843825578689575\n",
            "Epoch 10: Loss 0.4116630256175995\n",
            "Epoch 20: Loss 0.2973274290561676\n",
            "Epoch 30: Loss 0.24203188717365265\n",
            "Epoch 40: Loss 0.20586766302585602\n",
            "Epoch 50: Loss 0.17445529997348785\n",
            "Epoch 60: Loss 0.144143208861351\n",
            "Epoch 70: Loss 0.11452476680278778\n",
            "Epoch 80: Loss 0.0868244394659996\n",
            "Epoch 90: Loss 0.0663197711110115\n",
            "Epoch 100: Loss 0.048102058470249176\n",
            "Epoch 110: Loss 0.03553037345409393\n",
            "Epoch 120: Loss 0.0260606799274683\n",
            "Epoch 130: Loss 0.02254015952348709\n",
            "Epoch 140: Loss 0.22377559542655945\n",
            "Epoch 150: Loss 0.08295188099145889\n",
            "Epoch 160: Loss 0.0530257411301136\n",
            "Epoch 170: Loss 0.03368096426129341\n",
            "Epoch 180: Loss 0.025572119280695915\n",
            "Epoch 190: Loss 0.019758539274334908\n",
            "Epoch 200: Loss 0.016412559896707535\n",
            "Epoch 210: Loss 0.014147858135402203\n",
            "Epoch 220: Loss 0.01257648877799511\n",
            "Epoch 230: Loss 0.011430134996771812\n",
            "Epoch 240: Loss 0.010559734888374805\n",
            "Epoch 250: Loss 0.009864266030490398\n",
            "Epoch 260: Loss 0.009296782314777374\n",
            "Epoch 270: Loss 0.008841526694595814\n",
            "Epoch 280: Loss 0.00847160629928112\n",
            "Epoch 290: Loss 0.008159271441400051\n",
            "Epoch 300: Loss 0.007892097346484661\n",
            "Epoch 310: Loss 0.0076704127714037895\n",
            "Epoch 320: Loss 0.007553884759545326\n",
            "Epoch 330: Loss 0.00729419244453311\n",
            "Epoch 340: Loss 0.007261231075972319\n",
            "Epoch 350: Loss 0.007067312486469746\n",
            "Epoch 360: Loss 0.007415641564875841\n",
            "Epoch 370: Loss 0.007099749054759741\n",
            "Epoch 380: Loss 0.006685612723231316\n",
            "Epoch 390: Loss 0.006512991618365049\n",
            "Epoch 400: Loss 0.006755811627954245\n",
            "Epoch 410: Loss 0.6960649490356445\n",
            "Epoch 420: Loss 0.15873150527477264\n",
            "Epoch 430: Loss 0.10650037229061127\n",
            "Epoch 440: Loss 0.0780320093035698\n",
            "Epoch 450: Loss 0.0580105222761631\n",
            "Epoch 460: Loss 0.04436802119016647\n",
            "Epoch 470: Loss 0.03433932363986969\n",
            "Epoch 480: Loss 0.0273447223007679\n",
            "Epoch 490: Loss 0.022349292412400246\n",
            "Epoch 500: Loss 0.01878228969871998\n",
            "Epoch 510: Loss 0.016187138855457306\n",
            "Epoch 520: Loss 0.014235722832381725\n",
            "Epoch 530: Loss 0.012756980955600739\n",
            "Epoch 540: Loss 0.011605811305344105\n",
            "Epoch 550: Loss 0.01069882232695818\n",
            "Epoch 560: Loss 0.00995677150785923\n",
            "Epoch 570: Loss 0.009344397112727165\n",
            "Epoch 580: Loss 0.008833448402583599\n",
            "Epoch 590: Loss 0.008405188098549843\n",
            "Epoch 600: Loss 0.008045687340199947\n",
            "Epoch 610: Loss 0.00773546751588583\n",
            "Epoch 620: Loss 0.007469693664461374\n",
            "Epoch 630: Loss 0.007235617842525244\n",
            "Epoch 640: Loss 0.007031973451375961\n",
            "Epoch 650: Loss 0.006851167883723974\n",
            "Epoch 660: Loss 0.0066930376924574375\n",
            "Epoch 670: Loss 0.0065564559772610664\n",
            "Epoch 680: Loss 0.006434010341763496\n",
            "Epoch 690: Loss 0.006321646738797426\n",
            "Epoch 700: Loss 0.006223381031304598\n",
            "Epoch 710: Loss 0.006133678834885359\n",
            "Epoch 720: Loss 0.006048630923032761\n",
            "Epoch 730: Loss 0.0059667592868208885\n",
            "Epoch 740: Loss 0.005892820190638304\n",
            "Epoch 750: Loss 0.005825409200042486\n",
            "Epoch 760: Loss 0.005761000793427229\n",
            "Epoch 770: Loss 0.005698579829186201\n",
            "Epoch 780: Loss 0.005644668824970722\n",
            "Epoch 790: Loss 0.005598211195319891\n",
            "Epoch 800: Loss 0.005554512143135071\n",
            "Epoch 810: Loss 0.005520899314433336\n",
            "Epoch 820: Loss 0.005487437825649977\n",
            "Epoch 830: Loss 0.005451650358736515\n",
            "Epoch 840: Loss 0.005423964466899633\n",
            "Epoch 850: Loss 0.005414838436990976\n",
            "Epoch 860: Loss 0.005389937199652195\n",
            "Epoch 870: Loss 0.005380458664149046\n",
            "Epoch 880: Loss 0.005376438610255718\n",
            "Epoch 890: Loss 0.005389741621911526\n",
            "Epoch 900: Loss 0.005474370438605547\n",
            "Epoch 910: Loss 0.0054558743722736835\n",
            "Epoch 920: Loss 0.0058733075857162476\n",
            "Epoch 930: Loss 0.6329471468925476\n",
            "Epoch 940: Loss 0.33951234817504883\n",
            "Epoch 950: Loss 0.309129923582077\n",
            "Epoch 960: Loss 0.266790509223938\n",
            "Epoch 970: Loss 0.2406289428472519\n",
            "Epoch 980: Loss 0.22334733605384827\n",
            "Epoch 990: Loss 0.20738476514816284\n",
            "\n",
            "\n",
            "MODEL VALIDATION:\n",
            "\n",
            "Validation F1 score: 0.8647887323943662\n",
            "\n",
            "\n",
            "MODEL TEST:\n",
            "\n",
            "Test F1 score: 0.8823529411764706\n"
          ]
        }
      ],
      "source": [
        "train_model(model, \"MLP\", data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Aproximación I - GCNMLP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "Ftkl9IapUI5v"
      },
      "outputs": [],
      "source": [
        "class GCNMLP(Module):\n",
        "\n",
        "    def __init__(self, num_features, num_classes, hidden_channels=32, n_layers=2):\n",
        "        super(GCNMLP, self).__init__()\n",
        "        self.gcn = GCN(\n",
        "            in_channels=num_features,\n",
        "            hidden_channels=hidden_channels,\n",
        "            num_layers=n_layers,\n",
        "            out_channels=hidden_channels,\n",
        "        )\n",
        "        self.cls = MLP(\n",
        "            in_channels=hidden_channels,\n",
        "            hidden_channels=hidden_channels,\n",
        "            out_channels=num_classes,\n",
        "            num_layers=2,\n",
        "            dropout=0.5\n",
        "        )\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        self.gcn.reset_parameters()\n",
        "        self.cls.reset_parameters()\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        x = self.gcn(x, edge_index)\n",
        "        x = self.cls(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "VjsJmmx_02Ht"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "===============================================================================================\n",
            "Layer (type:depth-idx)                        Output Shape              Param #\n",
            "===============================================================================================\n",
            "├─GCN: 1-1                                    [-1, 48]                  --\n",
            "|    └─ModuleList: 2                          []                        --\n",
            "|    |    └─GCNConv: 3-1                      [-1, 48]                  24,048\n",
            "|    └─ModuleList: 2                          []                        --\n",
            "|    |    └─Identity: 3-2                     [-1, 48]                  --\n",
            "|    └─ReLU: 2-1                              [-1, 48]                  --\n",
            "|    └─Dropout: 2-2                           [-1, 48]                  --\n",
            "|    └─ModuleList: 2                          []                        --\n",
            "|    |    └─GCNConv: 3-3                      [-1, 48]                  2,352\n",
            "|    └─ModuleList: 2                          []                        --\n",
            "|    |    └─Identity: 3-4                     [-1, 48]                  --\n",
            "|    └─ReLU: 2-3                              [-1, 48]                  --\n",
            "|    └─Dropout: 2-4                           [-1, 48]                  --\n",
            "|    └─ModuleList: 2                          []                        --\n",
            "|    |    └─GCNConv: 3-5                      [-1, 48]                  2,352\n",
            "|    └─ModuleList: 2                          []                        --\n",
            "|    |    └─Identity: 3-6                     [-1, 48]                  --\n",
            "|    └─ReLU: 2-5                              [-1, 48]                  --\n",
            "|    └─Dropout: 2-6                           [-1, 48]                  --\n",
            "|    └─ModuleList: 2                          []                        --\n",
            "|    |    └─GCNConv: 3-7                      [-1, 48]                  2,352\n",
            "|    └─ModuleList: 2                          []                        --\n",
            "|    |    └─Identity: 3-8                     [-1, 48]                  --\n",
            "|    └─ReLU: 2-7                              [-1, 48]                  --\n",
            "|    └─Dropout: 2-8                           [-1, 48]                  --\n",
            "|    └─ModuleList: 2                          []                        --\n",
            "|    |    └─GCNConv: 3-9                      [-1, 48]                  2,352\n",
            "├─MLP: 1-2                                    [-1, 3]                   --\n",
            "|    └─ModuleList: 2                          []                        --\n",
            "|    |    └─Linear: 3-10                      [-1, 48]                  2,352\n",
            "|    └─ModuleList: 2                          []                        --\n",
            "|    |    └─BatchNorm: 3-11                   [-1, 48]                  96\n",
            "|    └─ReLU: 2-9                              [-1, 48]                  --\n",
            "|    └─ModuleList: 2                          []                        --\n",
            "|    |    └─Linear: 3-12                      [-1, 3]                   147\n",
            "===============================================================================================\n",
            "Total params: 36,051\n",
            "Trainable params: 36,051\n",
            "Non-trainable params: 0\n",
            "Total mult-adds (M): 0.10\n",
            "===============================================================================================\n",
            "Input size (MB): 38.28\n",
            "Forward/backward pass size (MB): 0.00\n",
            "Params size (MB): 0.14\n",
            "Estimated Total Size (MB): 38.42\n",
            "===============================================================================================\n"
          ]
        }
      ],
      "source": [
        "model = GCNMLP(\n",
        "    dataset.num_node_features,\n",
        "    dataset.num_classes,\n",
        "    hidden_channels=48,\n",
        "    n_layers=5\n",
        ")\n",
        "\n",
        "model.reset_parameters()\n",
        "\n",
        "summary(model, (data.x, data.edge_index));"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 0: Loss 1.2077999114990234\n",
            "Epoch 10: Loss 0.4996836185455322\n",
            "Epoch 20: Loss 0.4365994334220886\n",
            "Epoch 30: Loss 0.4047237038612366\n",
            "Epoch 40: Loss 0.38854464888572693\n",
            "Epoch 50: Loss 0.3696742057800293\n",
            "Epoch 60: Loss 0.3636935353279114\n",
            "Epoch 70: Loss 0.35430899262428284\n",
            "Epoch 80: Loss 0.34106239676475525\n",
            "Epoch 90: Loss 0.33254262804985046\n",
            "Epoch 100: Loss 0.35580161213874817\n",
            "Epoch 110: Loss 0.33820101618766785\n",
            "Epoch 120: Loss 0.3087595999240875\n",
            "Epoch 130: Loss 0.2984614968299866\n",
            "Epoch 140: Loss 0.2713417112827301\n",
            "Epoch 150: Loss 0.2598479390144348\n",
            "Epoch 160: Loss 0.2249542623758316\n",
            "Epoch 170: Loss 0.2201988846063614\n",
            "Epoch 180: Loss 0.18764100968837738\n",
            "Epoch 190: Loss 0.3337077498435974\n",
            "Epoch 200: Loss 0.2484051138162613\n",
            "Epoch 210: Loss 0.19789768755435944\n",
            "Epoch 220: Loss 0.1736476719379425\n",
            "Epoch 230: Loss 0.1485978364944458\n",
            "Epoch 240: Loss 0.20343264937400818\n",
            "Epoch 250: Loss 0.16440783441066742\n",
            "Epoch 260: Loss 0.13412795960903168\n",
            "Epoch 270: Loss 0.1294499784708023\n",
            "Epoch 280: Loss 0.1119399443268776\n",
            "Epoch 290: Loss 0.31938955187797546\n",
            "Epoch 300: Loss 0.23110520839691162\n",
            "Epoch 310: Loss 0.16704341769218445\n",
            "Epoch 320: Loss 0.13492238521575928\n",
            "Epoch 330: Loss 0.11579573154449463\n",
            "Epoch 340: Loss 0.10586755722761154\n",
            "Epoch 350: Loss 0.15985994040966034\n",
            "Epoch 360: Loss 0.1218598261475563\n",
            "Epoch 370: Loss 0.10110502690076828\n",
            "Epoch 380: Loss 0.09225146472454071\n",
            "Epoch 390: Loss 0.1035003811120987\n",
            "Epoch 400: Loss 0.08564193546772003\n",
            "Epoch 410: Loss 0.21771939098834991\n",
            "Epoch 420: Loss 0.14637403190135956\n",
            "Epoch 430: Loss 0.1143769696354866\n",
            "Epoch 440: Loss 0.09468220174312592\n",
            "Epoch 450: Loss 0.08459998667240143\n",
            "Epoch 460: Loss 0.07636357843875885\n",
            "Epoch 470: Loss 0.19981496036052704\n",
            "Epoch 480: Loss 0.12412336468696594\n",
            "Epoch 490: Loss 0.09417202323675156\n",
            "Epoch 500: Loss 0.08158394694328308\n",
            "Epoch 510: Loss 0.07377493381500244\n",
            "Epoch 520: Loss 0.07834095507860184\n",
            "Epoch 530: Loss 0.06615457683801651\n",
            "Epoch 540: Loss 0.08554364740848541\n",
            "Epoch 550: Loss 0.25988441705703735\n",
            "Epoch 560: Loss 0.18973520398139954\n",
            "Epoch 570: Loss 0.14075499773025513\n",
            "Epoch 580: Loss 0.11240198463201523\n",
            "Epoch 590: Loss 0.09423557668924332\n",
            "Epoch 600: Loss 0.08278607577085495\n",
            "Epoch 610: Loss 0.08048085123300552\n",
            "Epoch 620: Loss 0.07347501814365387\n",
            "Epoch 630: Loss 0.07356394827365875\n",
            "Epoch 640: Loss 0.1998409777879715\n",
            "Epoch 650: Loss 0.13075202703475952\n",
            "Epoch 660: Loss 0.10005708783864975\n",
            "Epoch 670: Loss 0.08213797956705093\n",
            "Epoch 680: Loss 0.0729585587978363\n",
            "Epoch 690: Loss 0.06821081042289734\n",
            "Epoch 700: Loss 0.07028317451477051\n",
            "Epoch 710: Loss 0.06224624440073967\n",
            "Epoch 720: Loss 0.15696632862091064\n",
            "Epoch 730: Loss 0.09569179266691208\n",
            "Epoch 740: Loss 0.07663308084011078\n",
            "Epoch 750: Loss 0.06489743292331696\n",
            "Epoch 760: Loss 0.057860881090164185\n",
            "Epoch 770: Loss 0.0552084781229496\n",
            "Epoch 780: Loss 0.05431925505399704\n",
            "Epoch 790: Loss 0.06719477474689484\n",
            "Epoch 800: Loss 0.06828130781650543\n",
            "Epoch 810: Loss 0.06588438153266907\n",
            "Epoch 820: Loss 0.05762035399675369\n",
            "Epoch 830: Loss 0.055818356573581696\n",
            "Epoch 840: Loss 0.05033819004893303\n",
            "Epoch 850: Loss 0.2388864904642105\n",
            "Epoch 860: Loss 0.12314090877771378\n",
            "Epoch 870: Loss 0.09065845608711243\n",
            "Epoch 880: Loss 0.0712018758058548\n",
            "Epoch 890: Loss 0.06152249872684479\n",
            "Epoch 900: Loss 0.05466654151678085\n",
            "Epoch 910: Loss 0.05048924684524536\n",
            "Epoch 920: Loss 0.04898946359753609\n",
            "Epoch 930: Loss 0.20796231925487518\n",
            "Epoch 940: Loss 0.2212638109922409\n",
            "Epoch 950: Loss 0.1464550793170929\n",
            "Epoch 960: Loss 0.10950951278209686\n",
            "Epoch 970: Loss 0.08857513964176178\n",
            "Epoch 980: Loss 0.07394532114267349\n",
            "Epoch 990: Loss 0.06676273047924042\n",
            "\n",
            "\n",
            "MODEL VALIDATION:\n",
            "\n",
            "Validation F1 score: 0.824225352112676\n",
            "\n",
            "\n",
            "MODEL TEST:\n",
            "\n",
            "Test F1 score: 0.8468559837728195\n"
          ]
        }
      ],
      "source": [
        "train_model(model, \"GCNMLP\", data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Aproximación II - GINMLP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "zFgcYv9nU9Hn"
      },
      "outputs": [],
      "source": [
        "class GINMLP(Module):\n",
        "\n",
        "    def __init__(self, num_features, num_classes, hidden_channels=32, n_layers=2):\n",
        "        super(GINMLP, self).__init__()\n",
        "        self.gcn = GIN(\n",
        "            in_channels=num_features,\n",
        "            hidden_channels=hidden_channels,\n",
        "            num_layers=n_layers,\n",
        "            out_channels=hidden_channels,\n",
        "            dropout=0.5,\n",
        "            act=\"relu\",\n",
        "            jk=\"cat\"\n",
        "        )\n",
        "        self.cls = MLP(\n",
        "            in_channels=hidden_channels,\n",
        "            hidden_channels=hidden_channels,\n",
        "            out_channels=num_classes,\n",
        "            num_layers=2,\n",
        "            dropout=0.5\n",
        "        )\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        self.gcn.reset_parameters()\n",
        "        self.cls.reset_parameters()\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        x = self.gcn(x, edge_index)\n",
        "        x = self.cls(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "pSSr2o0pVESE"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==========================================================================================\n",
            "Layer (type:depth-idx)                   Output Shape              Param #\n",
            "==========================================================================================\n",
            "├─GCN: 1-1                               [-1, 32]                  --\n",
            "|    └─ModuleList: 2                     []                        --\n",
            "|    |    └─GCNConv: 3-1                 [-1, 32]                  16,032\n",
            "|    └─ModuleList: 2                     []                        --\n",
            "|    |    └─Identity: 3-2                [-1, 32]                  --\n",
            "|    └─ReLU: 2-1                         [-1, 32]                  --\n",
            "|    └─Dropout: 2-2                      [-1, 32]                  --\n",
            "|    └─ModuleList: 2                     []                        --\n",
            "|    |    └─GCNConv: 3-3                 [-1, 32]                  1,056\n",
            "|    └─ModuleList: 2                     []                        --\n",
            "|    |    └─Identity: 3-4                [-1, 32]                  --\n",
            "|    └─ReLU: 2-3                         [-1, 32]                  --\n",
            "|    └─Dropout: 2-4                      [-1, 32]                  --\n",
            "|    └─ModuleList: 2                     []                        --\n",
            "|    |    └─GCNConv: 3-5                 [-1, 32]                  1,056\n",
            "├─MLP: 1-2                               [-1, 3]                   --\n",
            "|    └─ModuleList: 2                     []                        --\n",
            "|    |    └─Linear: 3-6                  [-1, 32]                  1,056\n",
            "|    └─ModuleList: 2                     []                        --\n",
            "|    |    └─BatchNorm: 3-7               [-1, 32]                  64\n",
            "|    └─ReLU: 2-5                         [-1, 32]                  --\n",
            "|    └─ModuleList: 2                     []                        --\n",
            "|    |    └─Linear: 3-8                  [-1, 3]                   99\n",
            "==========================================================================================\n",
            "Total params: 19,363\n",
            "Trainable params: 19,363\n",
            "Non-trainable params: 0\n",
            "Total mult-adds (M): 0.06\n",
            "==========================================================================================\n",
            "Input size (MB): 38.28\n",
            "Forward/backward pass size (MB): 0.00\n",
            "Params size (MB): 0.07\n",
            "Estimated Total Size (MB): 38.36\n",
            "==========================================================================================\n"
          ]
        }
      ],
      "source": [
        "model = GCNMLP(\n",
        "    dataset.num_node_features,\n",
        "    dataset.num_classes,\n",
        "    hidden_channels=32,\n",
        "    n_layers=3\n",
        ")\n",
        "\n",
        "model.reset_parameters()\n",
        "\n",
        "summary(model, (data.x, data.edge_index));"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 0: Loss 1.2594114542007446\n",
            "Epoch 10: Loss 0.4906434416770935\n",
            "Epoch 20: Loss 0.40114662051200867\n",
            "Epoch 30: Loss 0.3634234070777893\n",
            "Epoch 40: Loss 0.334707647562027\n",
            "Epoch 50: Loss 0.31895121932029724\n",
            "Epoch 60: Loss 0.2969702482223511\n",
            "Epoch 70: Loss 0.2792932391166687\n",
            "Epoch 80: Loss 0.25620272755622864\n",
            "Epoch 90: Loss 0.24893979728221893\n",
            "Epoch 100: Loss 0.2190689891576767\n",
            "Epoch 110: Loss 0.20904359221458435\n",
            "Epoch 120: Loss 0.19074948132038116\n",
            "Epoch 130: Loss 0.16124306619167328\n",
            "Epoch 140: Loss 0.14611603319644928\n",
            "Epoch 150: Loss 0.13722538948059082\n",
            "Epoch 160: Loss 0.13242106139659882\n",
            "Epoch 170: Loss 0.11777135729789734\n",
            "Epoch 180: Loss 0.10827633738517761\n",
            "Epoch 190: Loss 0.10088731348514557\n",
            "Epoch 200: Loss 0.10480557382106781\n",
            "Epoch 210: Loss 0.1816914975643158\n",
            "Epoch 220: Loss 0.12330549210309982\n",
            "Epoch 230: Loss 0.09609872847795486\n",
            "Epoch 240: Loss 0.0807417780160904\n",
            "Epoch 250: Loss 0.0694575086236\n",
            "Epoch 260: Loss 0.14169296622276306\n",
            "Epoch 270: Loss 0.13481922447681427\n",
            "Epoch 280: Loss 0.0958668664097786\n",
            "Epoch 290: Loss 0.07306784391403198\n",
            "Epoch 300: Loss 0.06257670372724533\n",
            "Epoch 310: Loss 0.05574589967727661\n",
            "Epoch 320: Loss 0.05190914124250412\n",
            "Epoch 330: Loss 0.14884863793849945\n",
            "Epoch 340: Loss 0.09897158294916153\n",
            "Epoch 350: Loss 0.07649364322423935\n",
            "Epoch 360: Loss 0.0601760596036911\n",
            "Epoch 370: Loss 0.05260997265577316\n",
            "Epoch 380: Loss 0.047422267496585846\n",
            "Epoch 390: Loss 0.31651487946510315\n",
            "Epoch 400: Loss 0.21898908913135529\n",
            "Epoch 410: Loss 0.16813595592975616\n",
            "Epoch 420: Loss 0.1335296332836151\n",
            "Epoch 430: Loss 0.10302296280860901\n",
            "Epoch 440: Loss 0.08569615334272385\n",
            "Epoch 450: Loss 0.0724533423781395\n",
            "Epoch 460: Loss 0.06216506287455559\n",
            "Epoch 470: Loss 0.05892698094248772\n",
            "Epoch 480: Loss 0.05054550990462303\n",
            "Epoch 490: Loss 0.05803365260362625\n",
            "Epoch 500: Loss 0.06194739043712616\n",
            "Epoch 510: Loss 0.056024469435214996\n",
            "Epoch 520: Loss 0.058500394225120544\n",
            "Epoch 530: Loss 0.05660135671496391\n",
            "Epoch 540: Loss 0.04912964999675751\n",
            "Epoch 550: Loss 0.0402672253549099\n",
            "Epoch 560: Loss 0.03621663153171539\n",
            "Epoch 570: Loss 0.035278864204883575\n",
            "Epoch 580: Loss 0.5996372699737549\n",
            "Epoch 590: Loss 0.28818878531455994\n",
            "Epoch 600: Loss 0.23679186403751373\n",
            "Epoch 610: Loss 0.18670207262039185\n",
            "Epoch 620: Loss 0.1488785445690155\n",
            "Epoch 630: Loss 0.11630935966968536\n",
            "Epoch 640: Loss 0.09438198059797287\n",
            "Epoch 650: Loss 0.08277800679206848\n",
            "Epoch 660: Loss 0.07233356684446335\n",
            "Epoch 670: Loss 0.06424020230770111\n",
            "Epoch 680: Loss 0.06082473695278168\n",
            "Epoch 690: Loss 0.05691676586866379\n",
            "Epoch 700: Loss 0.05321695655584335\n",
            "Epoch 710: Loss 0.04747181758284569\n",
            "Epoch 720: Loss 0.04739823564887047\n",
            "Epoch 730: Loss 0.04886915162205696\n",
            "Epoch 740: Loss 0.053948353976011276\n",
            "Epoch 750: Loss 0.04144204035401344\n",
            "Epoch 760: Loss 0.051911283284425735\n",
            "Epoch 770: Loss 0.07007060945034027\n",
            "Epoch 780: Loss 0.0525827594101429\n",
            "Epoch 790: Loss 0.04298967495560646\n",
            "Epoch 800: Loss 0.037917088717222214\n",
            "Epoch 810: Loss 0.03777720779180527\n",
            "Epoch 820: Loss 0.04795583710074425\n",
            "Epoch 830: Loss 0.046573806554079056\n",
            "Epoch 840: Loss 0.041475601494312286\n",
            "Epoch 850: Loss 0.03913784772157669\n",
            "Epoch 860: Loss 0.03140584006905556\n",
            "Epoch 870: Loss 0.02941952273249626\n",
            "Epoch 880: Loss 0.027018427848815918\n",
            "Epoch 890: Loss 0.7479308247566223\n",
            "Epoch 900: Loss 0.34393247961997986\n",
            "Epoch 910: Loss 0.28080233931541443\n",
            "Epoch 920: Loss 0.2456550896167755\n",
            "Epoch 930: Loss 0.20953814685344696\n",
            "Epoch 940: Loss 0.183901846408844\n",
            "Epoch 950: Loss 0.16151149570941925\n",
            "Epoch 960: Loss 0.14418353140354156\n",
            "Epoch 970: Loss 0.13096356391906738\n",
            "Epoch 980: Loss 0.11836370825767517\n",
            "Epoch 990: Loss 0.1052817851305008\n",
            "\n",
            "\n",
            "MODEL VALIDATION:\n",
            "\n",
            "Validation F1 score: 0.851830985915493\n",
            "\n",
            "\n",
            "MODEL TEST:\n",
            "\n",
            "Test F1 score: 0.8539553752535497\n"
          ]
        }
      ],
      "source": [
        "train_model(model, \"GINMLP\", data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Aproximación III - Convolucional"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "tiEH1JK_XLm7"
      },
      "outputs": [],
      "source": [
        "class Convolucional(nn.Module):\n",
        "    def __init__(self, in_channels, hidden_channels, out_channels, dropout_rate=0.5):\n",
        "        super(Convolucional, self).__init__()\n",
        "\n",
        "        self.dropout_rate = dropout_rate\n",
        "\n",
        "        # Capas de GNN\n",
        "        self.gcn1 = GCNConv(in_channels, hidden_channels)\n",
        "        self.gcn2 = GCNConv(hidden_channels, hidden_channels)\n",
        "        self.gat = GATConv(hidden_channels, hidden_channels, heads=8, concat=False)\n",
        "        self.gcn3 = GCNConv(hidden_channels, hidden_channels)\n",
        "\n",
        "        # Capas densas (más profundas)\n",
        "        self.fc1 = nn.Linear(hidden_channels, hidden_channels // 2)\n",
        "        self.fc2 = nn.Linear(hidden_channels // 2, hidden_channels // 4)\n",
        "        self.fc3 = nn.Linear(hidden_channels // 4, hidden_channels // 8)\n",
        "        self.fc4 = nn.Linear(hidden_channels // 8, out_channels)\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        # Capas GCN y GAT\n",
        "        x = F.relu(self.gcn1(x, edge_index))\n",
        "        x = F.dropout(x, p=self.dropout_rate, training=self.training)\n",
        "\n",
        "        x = F.relu(self.gcn2(x, edge_index))\n",
        "        x = F.dropout(x, p=self.dropout_rate, training=self.training)\n",
        "\n",
        "        x = F.relu(self.gat(x, edge_index))\n",
        "        x = F.dropout(x, p=self.dropout_rate, training=self.training)\n",
        "\n",
        "        x = F.relu(self.gcn3(x, edge_index))\n",
        "        x = F.dropout(x, p=self.dropout_rate, training=self.training)\n",
        "\n",
        "        # Capas densas finales\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.dropout(x, p=self.dropout_rate, training=self.training)\n",
        "\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = F.dropout(x, p=self.dropout_rate, training=self.training)\n",
        "\n",
        "        x = F.relu(self.fc3(x))\n",
        "        x = F.dropout(x, p=self.dropout_rate, training=self.training)\n",
        "\n",
        "        x = self.fc4(x)  # Capa final sin activación, log-softmax al final\n",
        "\n",
        "        return x.log_softmax(dim=-1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "ee7K0WCBXN0B"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==========================================================================================\n",
            "Layer (type:depth-idx)                   Output Shape              Param #\n",
            "==========================================================================================\n",
            "├─GCNConv: 1-1                           [-1, 64]                  --\n",
            "|    └─Linear: 2-1                       [-1, 64]                  32,000\n",
            "|    └─SumAggregation: 2-2               [-1, 64]                  --\n",
            "├─GCNConv: 1-2                           [-1, 64]                  --\n",
            "|    └─Linear: 2-3                       [-1, 64]                  4,096\n",
            "|    └─SumAggregation: 2-4               [-1, 64]                  --\n",
            "├─GATConv: 1-3                           [-1, 64]                  --\n",
            "|    └─Linear: 2-5                       [-1, 512]                 32,768\n",
            "|    └─SumAggregation: 2-6               [-1, 8, 64]               --\n",
            "├─GCNConv: 1-4                           [-1, 64]                  --\n",
            "|    └─Linear: 2-7                       [-1, 64]                  4,096\n",
            "|    └─SumAggregation: 2-8               [-1, 64]                  --\n",
            "├─Linear: 1-5                            [-1, 32]                  2,080\n",
            "├─Linear: 1-6                            [-1, 16]                  528\n",
            "├─Linear: 1-7                            [-1, 8]                   136\n",
            "├─Linear: 1-8                            [-1, 3]                   27\n",
            "==========================================================================================\n",
            "Total params: 75,731\n",
            "Trainable params: 75,731\n",
            "Non-trainable params: 0\n",
            "Total mult-adds (M): 0.15\n",
            "==========================================================================================\n",
            "Input size (MB): 38.28\n",
            "Forward/backward pass size (MB): 0.01\n",
            "Params size (MB): 0.29\n",
            "Estimated Total Size (MB): 38.58\n",
            "==========================================================================================\n"
          ]
        }
      ],
      "source": [
        "model = Convolucional(\n",
        "    dataset.num_node_features,\n",
        "    64,\n",
        "    dataset.num_classes\n",
        ")\n",
        "\n",
        "summary(model, (data.x, data.edge_index));"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 0: Loss 1.096235990524292\n",
            "Epoch 10: Loss 1.066545844078064\n",
            "Epoch 20: Loss 0.9763978123664856\n",
            "Epoch 30: Loss 0.9006969332695007\n",
            "Epoch 40: Loss 0.8095491528511047\n",
            "Epoch 50: Loss 0.7542150616645813\n",
            "Epoch 60: Loss 0.7230062484741211\n",
            "Epoch 70: Loss 0.7064228653907776\n",
            "Epoch 80: Loss 0.6937075853347778\n",
            "Epoch 90: Loss 0.696644127368927\n",
            "Epoch 100: Loss 0.6706656813621521\n",
            "Epoch 110: Loss 0.6702114343643188\n",
            "Epoch 120: Loss 0.699093222618103\n",
            "Epoch 130: Loss 0.6558680534362793\n",
            "Epoch 140: Loss 0.650458812713623\n",
            "Epoch 150: Loss 0.6328067183494568\n",
            "Epoch 160: Loss 0.6301537156105042\n",
            "Epoch 170: Loss 0.6395326852798462\n",
            "Epoch 180: Loss 0.6320286989212036\n",
            "Epoch 190: Loss 0.6216433048248291\n",
            "Epoch 200: Loss 0.6383740901947021\n",
            "Epoch 210: Loss 0.6028285026550293\n",
            "Epoch 220: Loss 0.6546435356140137\n",
            "Epoch 230: Loss 0.6227969527244568\n",
            "Epoch 240: Loss 0.5969386100769043\n",
            "Epoch 250: Loss 0.5828962922096252\n",
            "Epoch 260: Loss 0.5775119066238403\n",
            "Epoch 270: Loss 0.5745675563812256\n",
            "Epoch 280: Loss 0.5727126598358154\n",
            "Epoch 290: Loss 0.5631744861602783\n",
            "Epoch 300: Loss 0.583011269569397\n",
            "Epoch 310: Loss 0.5607491731643677\n",
            "Epoch 320: Loss 0.5859190225601196\n",
            "Epoch 330: Loss 0.5690699815750122\n",
            "Epoch 340: Loss 0.5593583583831787\n",
            "Epoch 350: Loss 0.5463415384292603\n",
            "Epoch 360: Loss 0.5372723340988159\n",
            "Epoch 370: Loss 0.5598121881484985\n",
            "Epoch 380: Loss 0.5260441303253174\n",
            "Epoch 390: Loss 0.5058043003082275\n",
            "Epoch 400: Loss 0.4952097237110138\n",
            "Epoch 410: Loss 0.5011569857597351\n",
            "Epoch 420: Loss 0.46518823504447937\n",
            "Epoch 430: Loss 0.47080835700035095\n",
            "Epoch 440: Loss 0.5102421045303345\n",
            "Epoch 450: Loss 0.48015597462654114\n",
            "Epoch 460: Loss 0.4543350338935852\n",
            "Epoch 470: Loss 0.44744160771369934\n",
            "Epoch 480: Loss 0.44430088996887207\n",
            "Epoch 490: Loss 0.4316723644733429\n",
            "Epoch 500: Loss 0.44725027680397034\n",
            "Epoch 510: Loss 0.5137903094291687\n",
            "Epoch 520: Loss 0.5880220532417297\n",
            "Epoch 530: Loss 0.5525323152542114\n",
            "Epoch 540: Loss 0.5082728862762451\n",
            "Epoch 550: Loss 0.4920894205570221\n",
            "Epoch 560: Loss 0.4759339988231659\n",
            "Epoch 570: Loss 0.4619377851486206\n",
            "Epoch 580: Loss 0.46912771463394165\n",
            "Epoch 590: Loss 0.46626773476600647\n",
            "Epoch 600: Loss 0.4538406729698181\n",
            "Epoch 610: Loss 0.4523627460002899\n",
            "Epoch 620: Loss 0.46809324622154236\n",
            "Epoch 630: Loss 0.48436132073402405\n",
            "Epoch 640: Loss 0.4674040973186493\n",
            "Epoch 650: Loss 0.4532874822616577\n",
            "Epoch 660: Loss 0.45413079857826233\n",
            "Epoch 670: Loss 0.5022352933883667\n",
            "Epoch 680: Loss 0.4794584810733795\n",
            "Epoch 690: Loss 0.44528496265411377\n",
            "Epoch 700: Loss 0.4409334361553192\n",
            "Epoch 710: Loss 0.48193010687828064\n",
            "Epoch 720: Loss 0.45213085412979126\n",
            "Epoch 730: Loss 0.4590452015399933\n",
            "Epoch 740: Loss 0.45180177688598633\n",
            "Epoch 750: Loss 0.4432292878627777\n",
            "Epoch 760: Loss 0.4370238482952118\n",
            "Epoch 770: Loss 0.44581958651542664\n",
            "Epoch 780: Loss 0.42674723267555237\n",
            "Epoch 790: Loss 0.4354402720928192\n",
            "Epoch 800: Loss 0.4329075813293457\n",
            "Epoch 810: Loss 0.4272131025791168\n",
            "Epoch 820: Loss 0.4291907846927643\n",
            "Epoch 830: Loss 0.4428826868534088\n",
            "Epoch 840: Loss 0.44328391551971436\n",
            "Epoch 850: Loss 0.4306584298610687\n",
            "Epoch 860: Loss 0.434378057718277\n",
            "Epoch 870: Loss 0.4196397066116333\n",
            "Epoch 880: Loss 0.41888052225112915\n",
            "Epoch 890: Loss 0.43427640199661255\n",
            "Epoch 900: Loss 0.4363265931606293\n",
            "Epoch 910: Loss 0.4289369583129883\n",
            "Epoch 920: Loss 0.4361623227596283\n",
            "Epoch 930: Loss 0.45946747064590454\n",
            "Epoch 940: Loss 0.4382410943508148\n",
            "Epoch 950: Loss 0.428265243768692\n",
            "Epoch 960: Loss 0.43264925479888916\n",
            "Epoch 970: Loss 0.42162206768989563\n",
            "Epoch 980: Loss 0.4375683665275574\n",
            "Epoch 990: Loss 0.4424934983253479\n",
            "\n",
            "\n",
            "MODEL VALIDATION:\n",
            "\n",
            "Validation F1 score: 0.8512676056338028\n",
            "\n",
            "\n",
            "MODEL TEST:\n",
            "\n",
            "Test F1 score: 0.8706896551724138\n"
          ]
        }
      ],
      "source": [
        "train_model(model, \"Convolucional\", data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "f2dKfGRkczks"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import GCNConv, GATConv\n",
        "\n",
        "class Convolucional_Softmax(nn.Module):\n",
        "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
        "        super(Convolucional_Softmax, self).__init__()\n",
        "        self.gcn1 = GCNConv(in_channels, hidden_channels)\n",
        "        self.gat = GATConv(hidden_channels, hidden_channels, heads=3, concat=False)\n",
        "        self.gcn2 = GCNConv(hidden_channels, hidden_channels)\n",
        "        self.fc = nn.Linear(hidden_channels, out_channels)\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        # Primera capa GCN\n",
        "        x = F.relu(self.gcn1(x, edge_index))\n",
        "        # Atención con GAT\n",
        "        x = F.relu(self.gat(x, edge_index))\n",
        "        # Segunda capa GCN\n",
        "        x = F.relu(self.gcn2(x, edge_index))\n",
        "        # Clasificación final\n",
        "        x = self.fc(x)\n",
        "        return F.log_softmax(x, dim=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "yD0XNjJvc0ki"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==========================================================================================\n",
            "Layer (type:depth-idx)                   Output Shape              Param #\n",
            "==========================================================================================\n",
            "├─GCNConv: 1-1                           [-1, 1024]                --\n",
            "|    └─Linear: 2-1                       [-1, 1024]                512,000\n",
            "|    └─SumAggregation: 2-2               [-1, 1024]                --\n",
            "├─GATConv: 1-2                           [-1, 1024]                --\n",
            "|    └─Linear: 2-3                       [-1, 3072]                3,145,728\n",
            "|    └─SumAggregation: 2-4               [-1, 3, 1024]             --\n",
            "├─GCNConv: 1-3                           [-1, 1024]                --\n",
            "|    └─Linear: 2-5                       [-1, 1024]                1,048,576\n",
            "|    └─SumAggregation: 2-6               [-1, 1024]                --\n",
            "├─Linear: 1-4                            [-1, 3]                   3,075\n",
            "==========================================================================================\n",
            "Total params: 4,709,379\n",
            "Trainable params: 4,709,379\n",
            "Non-trainable params: 0\n",
            "Total mult-adds (M): 9.42\n",
            "==========================================================================================\n",
            "Input size (MB): 38.28\n",
            "Forward/backward pass size (MB): 0.04\n",
            "Params size (MB): 17.96\n",
            "Estimated Total Size (MB): 56.29\n",
            "==========================================================================================\n"
          ]
        }
      ],
      "source": [
        "model = Convolucional_Softmax(\n",
        "    dataset.num_node_features,\n",
        "    1024,\n",
        "    dataset.num_classes\n",
        ")\n",
        "\n",
        "summary(model, (data.x, data.edge_index));"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 0: Loss 1.096006155014038\n",
            "Epoch 10: Loss 0.7992937564849854\n",
            "Epoch 20: Loss 0.5070474743843079\n",
            "Epoch 30: Loss 0.36514607071876526\n",
            "Epoch 40: Loss 0.3134123980998993\n",
            "Epoch 50: Loss 0.2940802574157715\n",
            "Epoch 60: Loss 0.2696363925933838\n",
            "Epoch 70: Loss 0.262224018573761\n",
            "Epoch 80: Loss 0.24143455922603607\n",
            "Epoch 90: Loss 0.24101990461349487\n",
            "Epoch 100: Loss 0.21725502610206604\n",
            "Epoch 110: Loss 0.2603490948677063\n",
            "Epoch 120: Loss 0.2960161864757538\n",
            "Epoch 130: Loss 0.24564185738563538\n",
            "Epoch 140: Loss 0.2178538292646408\n",
            "Epoch 150: Loss 0.20738455653190613\n",
            "Epoch 160: Loss 0.19562767446041107\n",
            "Epoch 170: Loss 0.1819668561220169\n",
            "Epoch 180: Loss 0.1651497334241867\n",
            "Epoch 190: Loss 0.17580541968345642\n",
            "Epoch 200: Loss 0.1505514681339264\n",
            "Epoch 210: Loss 0.1546141356229782\n",
            "Epoch 220: Loss 0.22586721181869507\n",
            "Epoch 230: Loss 0.18088433146476746\n",
            "Epoch 240: Loss 0.15625999867916107\n",
            "Epoch 250: Loss 0.13560187816619873\n",
            "Epoch 260: Loss 0.15702039003372192\n",
            "Epoch 270: Loss 0.1265859603881836\n",
            "Epoch 280: Loss 0.11474460363388062\n",
            "Epoch 290: Loss 0.19819217920303345\n",
            "Epoch 300: Loss 0.17891952395439148\n",
            "Epoch 310: Loss 0.12837009131908417\n",
            "Epoch 320: Loss 0.10828816890716553\n",
            "Epoch 330: Loss 0.09991773217916489\n",
            "Epoch 340: Loss 0.09580004960298538\n",
            "Epoch 350: Loss 0.317374050617218\n",
            "Epoch 360: Loss 0.2119922637939453\n",
            "Epoch 370: Loss 0.1773737221956253\n",
            "Epoch 380: Loss 0.1460699588060379\n",
            "Epoch 390: Loss 0.15298935770988464\n",
            "Epoch 400: Loss 0.12378284335136414\n",
            "Epoch 410: Loss 0.10320370644330978\n",
            "Epoch 420: Loss 0.09400088340044022\n",
            "Epoch 430: Loss 0.08795531839132309\n",
            "Epoch 440: Loss 0.08963409811258316\n",
            "Epoch 450: Loss 0.09162876754999161\n",
            "Epoch 460: Loss 0.08360913395881653\n",
            "Epoch 470: Loss 0.07561317831277847\n",
            "Epoch 480: Loss 0.07436458766460419\n",
            "Epoch 490: Loss 0.9070671200752258\n",
            "Epoch 500: Loss 0.667502760887146\n",
            "Epoch 510: Loss 0.2651667296886444\n",
            "Epoch 520: Loss 0.19761662185192108\n",
            "Epoch 530: Loss 0.23743915557861328\n",
            "Epoch 540: Loss 0.16114100813865662\n",
            "Epoch 550: Loss 0.13340328633785248\n",
            "Epoch 560: Loss 0.12018130719661713\n",
            "Epoch 570: Loss 0.10383856296539307\n",
            "Epoch 580: Loss 0.09432070702314377\n",
            "Epoch 590: Loss 0.08433910459280014\n",
            "Epoch 600: Loss 0.2292642891407013\n",
            "Epoch 610: Loss 0.13960766792297363\n",
            "Epoch 620: Loss 0.10871170461177826\n",
            "Epoch 630: Loss 0.09239979088306427\n",
            "Epoch 640: Loss 0.08375708758831024\n",
            "Epoch 650: Loss 0.08660895377397537\n",
            "Epoch 660: Loss 0.07665742188692093\n",
            "Epoch 670: Loss 0.07282192260026932\n",
            "Epoch 680: Loss 0.07566194236278534\n",
            "Epoch 690: Loss 0.093124158680439\n",
            "Epoch 700: Loss 0.07300637662410736\n",
            "Epoch 710: Loss 0.06729862093925476\n",
            "Epoch 720: Loss 0.06287730485200882\n",
            "Epoch 730: Loss 0.060761094093322754\n",
            "Epoch 740: Loss 0.3818093240261078\n",
            "Epoch 750: Loss 0.14070741832256317\n",
            "Epoch 760: Loss 0.12252309918403625\n",
            "Epoch 770: Loss 0.09457514435052872\n",
            "Epoch 780: Loss 0.0748690590262413\n",
            "Epoch 790: Loss 0.06554912775754929\n",
            "Epoch 800: Loss 0.06145591288805008\n",
            "Epoch 810: Loss 0.06270529329776764\n",
            "Epoch 820: Loss 0.0596204549074173\n",
            "Epoch 830: Loss 0.05660023167729378\n",
            "Epoch 840: Loss 0.06802350282669067\n",
            "Epoch 850: Loss 0.08390651643276215\n",
            "Epoch 860: Loss 0.0678868442773819\n",
            "Epoch 870: Loss 0.05374383553862572\n",
            "Epoch 880: Loss 0.0540575236082077\n",
            "Epoch 890: Loss 0.04865870997309685\n",
            "Epoch 900: Loss 0.049480896443128586\n",
            "Epoch 910: Loss 0.047818414866924286\n",
            "Epoch 920: Loss 0.7419288158416748\n",
            "Epoch 930: Loss 0.695632815361023\n",
            "Epoch 940: Loss 0.34138253331184387\n",
            "Epoch 950: Loss 0.27610287070274353\n",
            "Epoch 960: Loss 0.2404351830482483\n",
            "Epoch 970: Loss 0.21109242737293243\n",
            "Epoch 980: Loss 0.19143155217170715\n",
            "Epoch 990: Loss 0.17452046275138855\n",
            "\n",
            "\n",
            "MODEL VALIDATION:\n",
            "\n",
            "Validation F1 score: 0.8664788732394366\n",
            "\n",
            "\n",
            "MODEL TEST:\n",
            "\n",
            "Test F1 score: 0.8940162271805274\n"
          ]
        }
      ],
      "source": [
        "train_model(model, \"Convolucional Softmax\", data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "kJ5nWyjofWwT"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import GCNConv, GATConv\n",
        "\n",
        "class Convolucional_Droput(nn.Module):\n",
        "    def __init__(self, in_channels, hidden_channels, out_channels, dropout_rate=0.5):\n",
        "        super(Convolucional_Droput, self).__init__()\n",
        "\n",
        "        # Capas de GNN\n",
        "        self.gcn1 = GCNConv(in_channels, hidden_channels)\n",
        "        self.gat = GATConv(hidden_channels, hidden_channels, heads=3, concat=False)\n",
        "        self.gcn2 = GCNConv(hidden_channels, hidden_channels)\n",
        "\n",
        "        # Capas densas finales\n",
        "        self.fc1 = nn.Linear(hidden_channels, hidden_channels // 2)\n",
        "        self.fc2 = nn.Linear(hidden_channels // 2, out_channels)\n",
        "\n",
        "        # Dropout rate\n",
        "        self.dropout_rate = dropout_rate\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        # Primera capa GCN\n",
        "        x = F.relu(self.gcn1(x, edge_index))\n",
        "        x = F.dropout(x, p=self.dropout_rate, training=self.training)\n",
        "\n",
        "        # Atención con GAT\n",
        "        x = F.relu(self.gat(x, edge_index))\n",
        "        x = F.dropout(x, p=self.dropout_rate, training=self.training)\n",
        "\n",
        "        # Segunda capa GCN\n",
        "        x = F.relu(self.gcn2(x, edge_index))\n",
        "        x = F.dropout(x, p=self.dropout_rate, training=self.training)\n",
        "\n",
        "        # Capas densas finales\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.dropout(x, p=self.dropout_rate, training=self.training)\n",
        "        x = self.fc2(x)\n",
        "\n",
        "        return F.log_softmax(x, dim=1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "TIZh0RC2fX0V"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==========================================================================================\n",
            "Layer (type:depth-idx)                   Output Shape              Param #\n",
            "==========================================================================================\n",
            "├─GCNConv: 1-1                           [-1, 1024]                --\n",
            "|    └─Linear: 2-1                       [-1, 1024]                512,000\n",
            "|    └─SumAggregation: 2-2               [-1, 1024]                --\n",
            "├─GATConv: 1-2                           [-1, 1024]                --\n",
            "|    └─Linear: 2-3                       [-1, 3072]                3,145,728\n",
            "|    └─SumAggregation: 2-4               [-1, 3, 1024]             --\n",
            "├─GCNConv: 1-3                           [-1, 1024]                --\n",
            "|    └─Linear: 2-5                       [-1, 1024]                1,048,576\n",
            "|    └─SumAggregation: 2-6               [-1, 1024]                --\n",
            "├─Linear: 1-4                            [-1, 512]                 524,800\n",
            "├─Linear: 1-5                            [-1, 3]                   1,539\n",
            "==========================================================================================\n",
            "Total params: 5,232,643\n",
            "Trainable params: 5,232,643\n",
            "Non-trainable params: 0\n",
            "Total mult-adds (M): 9.94\n",
            "==========================================================================================\n",
            "Input size (MB): 38.28\n",
            "Forward/backward pass size (MB): 0.04\n",
            "Params size (MB): 19.96\n",
            "Estimated Total Size (MB): 58.29\n",
            "==========================================================================================\n"
          ]
        }
      ],
      "source": [
        "model = Convolucional_Droput(\n",
        "    dataset.num_node_features,\n",
        "    1024,\n",
        "    dataset.num_classes\n",
        ")\n",
        "\n",
        "summary(model, (data.x, data.edge_index));"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 0: Loss 1.0996335744857788\n",
            "Epoch 10: Loss 1.026053786277771\n",
            "Epoch 20: Loss 0.9933344125747681\n",
            "Epoch 30: Loss 0.6683919429779053\n",
            "Epoch 40: Loss 0.45157840847969055\n",
            "Epoch 50: Loss 0.362957239151001\n",
            "Epoch 60: Loss 0.30965444445610046\n",
            "Epoch 70: Loss 0.27491268515586853\n",
            "Epoch 80: Loss 0.27760785818099976\n",
            "Epoch 90: Loss 0.25272268056869507\n",
            "Epoch 100: Loss 0.39860448241233826\n",
            "Epoch 110: Loss 0.24200154840946198\n",
            "Epoch 120: Loss 0.2265019565820694\n",
            "Epoch 130: Loss 0.2060878723859787\n",
            "Epoch 140: Loss 0.3056853115558624\n",
            "Epoch 150: Loss 0.2967986464500427\n",
            "Epoch 160: Loss 0.1987808346748352\n",
            "Epoch 170: Loss 0.16967228055000305\n",
            "Epoch 180: Loss 0.16424161195755005\n",
            "Epoch 190: Loss 0.6909733414649963\n",
            "Epoch 200: Loss 0.32860589027404785\n",
            "Epoch 210: Loss 0.24705252051353455\n",
            "Epoch 220: Loss 0.20823723077774048\n",
            "Epoch 230: Loss 0.18407605588436127\n",
            "Epoch 240: Loss 0.16994427144527435\n",
            "Epoch 250: Loss 0.18127544224262238\n",
            "Epoch 260: Loss 0.1597922146320343\n",
            "Epoch 270: Loss 0.16033954918384552\n",
            "Epoch 280: Loss 0.146884948015213\n",
            "Epoch 290: Loss 0.14171718060970306\n",
            "Epoch 300: Loss 0.16627547144889832\n",
            "Epoch 310: Loss 0.14584508538246155\n",
            "Epoch 320: Loss 0.13230255246162415\n",
            "Epoch 330: Loss 0.13059860467910767\n",
            "Epoch 340: Loss 0.2764759361743927\n",
            "Epoch 350: Loss 0.23191404342651367\n",
            "Epoch 360: Loss 0.16220945119857788\n",
            "Epoch 370: Loss 0.1424291431903839\n",
            "Epoch 380: Loss 0.14236141741275787\n",
            "Epoch 390: Loss 0.13262192904949188\n",
            "Epoch 400: Loss 0.12076471745967865\n",
            "Epoch 410: Loss 0.12195931375026703\n",
            "Epoch 420: Loss 0.9939297437667847\n",
            "Epoch 430: Loss 0.5660450458526611\n",
            "Epoch 440: Loss 0.3927464187145233\n",
            "Epoch 450: Loss 0.29930317401885986\n",
            "Epoch 460: Loss 0.2538718581199646\n",
            "Epoch 470: Loss 0.21475285291671753\n",
            "Epoch 480: Loss 0.2188204973936081\n",
            "Epoch 490: Loss 0.20404458045959473\n",
            "Epoch 500: Loss 0.17619921267032623\n",
            "Epoch 510: Loss 0.1726427674293518\n",
            "Epoch 520: Loss 0.16070778667926788\n",
            "Epoch 530: Loss 0.15229733288288116\n",
            "Epoch 540: Loss 0.35756716132164\n",
            "Epoch 550: Loss 0.2770989239215851\n",
            "Epoch 560: Loss 0.25085583329200745\n",
            "Epoch 570: Loss 0.18434815108776093\n",
            "Epoch 580: Loss 0.222966268658638\n",
            "Epoch 590: Loss 0.21007771790027618\n",
            "Epoch 600: Loss 0.19684164226055145\n",
            "Epoch 610: Loss 0.16327093541622162\n",
            "Epoch 620: Loss 0.15684272348880768\n",
            "Epoch 630: Loss 0.30387362837791443\n",
            "Epoch 640: Loss 0.19083672761917114\n",
            "Epoch 650: Loss 0.19214679300785065\n",
            "Epoch 660: Loss 0.1549728661775589\n",
            "Epoch 670: Loss 0.14964504539966583\n",
            "Epoch 680: Loss 0.14609096944332123\n",
            "Epoch 690: Loss 0.15325619280338287\n",
            "Epoch 700: Loss 0.14298318326473236\n",
            "Epoch 710: Loss 0.17916952073574066\n",
            "Epoch 720: Loss 0.1595938503742218\n",
            "Epoch 730: Loss 0.14497347176074982\n",
            "Epoch 740: Loss 0.14192894101142883\n",
            "Epoch 750: Loss 0.26696500182151794\n",
            "Epoch 760: Loss 0.20725490152835846\n",
            "Epoch 770: Loss 0.20269888639450073\n",
            "Epoch 780: Loss 0.15454252064228058\n",
            "Epoch 790: Loss 0.1790277361869812\n",
            "Epoch 800: Loss 0.20460717380046844\n",
            "Epoch 810: Loss 0.16219361126422882\n",
            "Epoch 820: Loss 0.1420707404613495\n",
            "Epoch 830: Loss 0.13790468871593475\n",
            "Epoch 840: Loss 0.1654287576675415\n",
            "Epoch 850: Loss 0.1372043490409851\n",
            "Epoch 860: Loss 0.13216115534305573\n",
            "Epoch 870: Loss 0.1640229970216751\n",
            "Epoch 880: Loss 0.13633163273334503\n",
            "Epoch 890: Loss 0.16239428520202637\n",
            "Epoch 900: Loss 0.13453271985054016\n",
            "Epoch 910: Loss 0.12705473601818085\n",
            "Epoch 920: Loss 0.1288955956697464\n",
            "Epoch 930: Loss 0.1226537674665451\n",
            "Epoch 940: Loss 0.15707987546920776\n",
            "Epoch 950: Loss 0.1941414326429367\n",
            "Epoch 960: Loss 0.15797735750675201\n",
            "Epoch 970: Loss 0.14395427703857422\n",
            "Epoch 980: Loss 0.6232195496559143\n",
            "Epoch 990: Loss 0.30595165491104126\n",
            "\n",
            "\n",
            "MODEL VALIDATION:\n",
            "\n",
            "Validation F1 score: 0.8839436619718309\n",
            "\n",
            "\n",
            "MODEL TEST:\n",
            "\n",
            "Test F1 score: 0.8960446247464503\n"
          ]
        }
      ],
      "source": [
        "train_model(model, \"Convolucional Dropout\", data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Aproximación IV - Graph Sage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "n4I4VyLoih8I"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import SAGEConv\n",
        "\n",
        "class GraphSAGEModel(torch.nn.Module):\n",
        "    def __init__(self, in_channels, hidden_channels, out_channels, dropout_rate=0.5):\n",
        "        super(GraphSAGEModel, self).__init__()\n",
        "\n",
        "        # Capas convolucionales\n",
        "        self.conv1 = SAGEConv(in_channels, hidden_channels)\n",
        "        self.conv2 = SAGEConv(hidden_channels, hidden_channels)\n",
        "        self.conv3 = SAGEConv(hidden_channels, hidden_channels)\n",
        "        self.conv4 = SAGEConv(hidden_channels, hidden_channels)\n",
        "\n",
        "        # Capas densas\n",
        "        self.fc1 = torch.nn.Linear(hidden_channels, hidden_channels // 2)\n",
        "        self.fc2 = torch.nn.Linear(hidden_channels // 2, hidden_channels // 4)\n",
        "        self.fc3 = torch.nn.Linear(hidden_channels // 4, out_channels)\n",
        "\n",
        "        # Dropout rate\n",
        "        self.dropout_rate = dropout_rate\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        # Capas convolucionales\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = F.relu(x)\n",
        "        x = self.conv2(x, edge_index)\n",
        "        x = F.relu(x)\n",
        "        x = self.conv3(x, edge_index)\n",
        "        x = F.relu(x)\n",
        "        x = self.conv4(x, edge_index)\n",
        "\n",
        "        # Capas densas\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.dropout(x, p=self.dropout_rate, training=self.training)\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = F.dropout(x, p=self.dropout_rate, training=self.training)\n",
        "        x = F.relu(self.fc3(x))\n",
        "\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "T6JftgCsikHu"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==========================================================================================\n",
            "Layer (type:depth-idx)                   Output Shape              Param #\n",
            "==========================================================================================\n",
            "├─SAGEConv: 1-1                          [-1, 64]                  --\n",
            "|    └─MeanAggregation: 2-1              [-1, 500]                 --\n",
            "|    └─Linear: 2-2                       [-1, 64]                  32,064\n",
            "|    └─Linear: 2-3                       [-1, 64]                  32,000\n",
            "├─SAGEConv: 1-2                          [-1, 64]                  --\n",
            "|    └─MeanAggregation: 2-4              [-1, 64]                  --\n",
            "|    └─Linear: 2-5                       [-1, 64]                  4,160\n",
            "|    └─Linear: 2-6                       [-1, 64]                  4,096\n",
            "├─SAGEConv: 1-3                          [-1, 64]                  --\n",
            "|    └─MeanAggregation: 2-7              [-1, 64]                  --\n",
            "|    └─Linear: 2-8                       [-1, 64]                  4,160\n",
            "|    └─Linear: 2-9                       [-1, 64]                  4,096\n",
            "├─SAGEConv: 1-4                          [-1, 64]                  --\n",
            "|    └─MeanAggregation: 2-10             [-1, 64]                  --\n",
            "|    └─Linear: 2-11                      [-1, 64]                  4,160\n",
            "|    └─Linear: 2-12                      [-1, 64]                  4,096\n",
            "├─Linear: 1-5                            [-1, 32]                  2,080\n",
            "├─Linear: 1-6                            [-1, 16]                  528\n",
            "├─Linear: 1-7                            [-1, 3]                   51\n",
            "==========================================================================================\n",
            "Total params: 91,491\n",
            "Trainable params: 91,491\n",
            "Non-trainable params: 0\n",
            "Total mult-adds (M): 0.18\n",
            "==========================================================================================\n",
            "Input size (MB): 38.28\n",
            "Forward/backward pass size (MB): 0.00\n",
            "Params size (MB): 0.35\n",
            "Estimated Total Size (MB): 38.64\n",
            "==========================================================================================\n"
          ]
        }
      ],
      "source": [
        "model = GraphSAGEModel(\n",
        "    dataset.num_node_features,\n",
        "    64,\n",
        "    dataset.num_classes\n",
        ")\n",
        "\n",
        "summary(model, (data.x, data.edge_index));"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 0: Loss 1.0985926389694214\n",
            "Epoch 10: Loss 0.9514390826225281\n",
            "Epoch 20: Loss 0.6820784211158752\n",
            "Epoch 30: Loss 0.6019129157066345\n",
            "Epoch 40: Loss 0.5170992016792297\n",
            "Epoch 50: Loss 0.4340762197971344\n",
            "Epoch 60: Loss 0.37244248390197754\n",
            "Epoch 70: Loss 0.3124355971813202\n",
            "Epoch 80: Loss 0.2872621715068817\n",
            "Epoch 90: Loss 0.2555478513240814\n",
            "Epoch 100: Loss 0.22297197580337524\n",
            "Epoch 110: Loss 0.2019387036561966\n",
            "Epoch 120: Loss 0.16028815507888794\n",
            "Epoch 130: Loss 0.13674601912498474\n",
            "Epoch 140: Loss 0.09733293205499649\n",
            "Epoch 150: Loss 0.07139457017183304\n",
            "Epoch 160: Loss 0.0527954064309597\n",
            "Epoch 170: Loss 0.05377450957894325\n",
            "Epoch 180: Loss 0.04727602005004883\n",
            "Epoch 190: Loss 0.04612891003489494\n",
            "Epoch 200: Loss 0.80464768409729\n",
            "Epoch 210: Loss 0.620771586894989\n",
            "Epoch 220: Loss 0.7197768092155457\n",
            "Epoch 230: Loss 0.4789150357246399\n",
            "Epoch 240: Loss 0.3774169385433197\n",
            "Epoch 250: Loss 0.2987455725669861\n",
            "Epoch 260: Loss 0.24987800419330597\n",
            "Epoch 270: Loss 0.2121734321117401\n",
            "Epoch 280: Loss 0.16802293062210083\n",
            "Epoch 290: Loss 0.38078925013542175\n",
            "Epoch 300: Loss 0.253905326128006\n",
            "Epoch 310: Loss 0.2080823928117752\n",
            "Epoch 320: Loss 0.1564820408821106\n",
            "Epoch 330: Loss 0.12757161259651184\n",
            "Epoch 340: Loss 0.10652314126491547\n",
            "Epoch 350: Loss 0.09656453877687454\n",
            "Epoch 360: Loss 0.11375808715820312\n",
            "Epoch 370: Loss 0.15811870992183685\n",
            "Epoch 380: Loss 0.08966445922851562\n",
            "Epoch 390: Loss 0.07136765867471695\n",
            "Epoch 400: Loss 0.06670480966567993\n",
            "Epoch 410: Loss 0.0639394000172615\n",
            "Epoch 420: Loss 0.06426090002059937\n",
            "Epoch 430: Loss 0.06061575934290886\n",
            "Epoch 440: Loss 0.06134236603975296\n",
            "Epoch 450: Loss 0.057589974254369736\n",
            "Epoch 460: Loss 0.0591336190700531\n",
            "Epoch 470: Loss 0.05862254276871681\n",
            "Epoch 480: Loss 0.05927542597055435\n",
            "Epoch 490: Loss 0.05649412050843239\n",
            "Epoch 500: Loss 0.060679804533720016\n",
            "Epoch 510: Loss 0.056075189262628555\n",
            "Epoch 520: Loss 0.05724913999438286\n",
            "Epoch 530: Loss 0.05518549680709839\n",
            "Epoch 540: Loss 0.05475831776857376\n",
            "Epoch 550: Loss 0.05393245071172714\n",
            "Epoch 560: Loss 0.052370503544807434\n",
            "Epoch 570: Loss 0.05298083648085594\n",
            "Epoch 580: Loss 0.05358973145484924\n",
            "Epoch 590: Loss 0.5527729988098145\n",
            "Epoch 600: Loss 0.4184783697128296\n",
            "Epoch 610: Loss 0.3641051948070526\n",
            "Epoch 620: Loss 0.29915088415145874\n",
            "Epoch 630: Loss 0.2550705075263977\n",
            "Epoch 640: Loss 0.22624072432518005\n",
            "Epoch 650: Loss 0.22299465537071228\n",
            "Epoch 660: Loss 0.1876610368490219\n",
            "Epoch 670: Loss 0.15680599212646484\n",
            "Epoch 680: Loss 0.13610132038593292\n",
            "Epoch 690: Loss 0.12563301622867584\n",
            "Epoch 700: Loss 0.3140186369419098\n",
            "Epoch 710: Loss 0.23805639147758484\n",
            "Epoch 720: Loss 0.17720812559127808\n",
            "Epoch 730: Loss 0.13695667684078217\n",
            "Epoch 740: Loss 0.11653276532888412\n",
            "Epoch 750: Loss 0.09894941002130508\n",
            "Epoch 760: Loss 0.09078551083803177\n",
            "Epoch 770: Loss 0.08639127761125565\n",
            "Epoch 780: Loss 0.09549508988857269\n",
            "Epoch 790: Loss 0.2606908977031708\n",
            "Epoch 800: Loss 0.15945494174957275\n",
            "Epoch 810: Loss 0.11066898703575134\n",
            "Epoch 820: Loss 0.0909508541226387\n",
            "Epoch 830: Loss 0.08209733664989471\n",
            "Epoch 840: Loss 0.0730823501944542\n",
            "Epoch 850: Loss 0.06916926801204681\n",
            "Epoch 860: Loss 0.06992965191602707\n",
            "Epoch 870: Loss 0.06824353337287903\n",
            "Epoch 880: Loss 0.07046468555927277\n",
            "Epoch 890: Loss 0.06552011519670486\n",
            "Epoch 900: Loss 0.07263561338186264\n",
            "Epoch 910: Loss 0.0747312605381012\n",
            "Epoch 920: Loss 0.07427322864532471\n",
            "Epoch 930: Loss 0.08131688833236694\n",
            "Epoch 940: Loss 0.07190705090761185\n",
            "Epoch 950: Loss 0.06330893188714981\n",
            "Epoch 960: Loss 0.060109611600637436\n",
            "Epoch 970: Loss 0.057084668427705765\n",
            "Epoch 980: Loss 0.05710441246628761\n",
            "Epoch 990: Loss 0.05509188026189804\n",
            "\n",
            "\n",
            "MODEL VALIDATION:\n",
            "\n",
            "Validation F1 score: 0.8546478873239437\n",
            "\n",
            "\n",
            "MODEL TEST:\n",
            "\n",
            "Test F1 score: 0.8732251521298174\n"
          ]
        }
      ],
      "source": [
        "train_model(model, \"Graph SAGE\", data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Comparación entre modelos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Separate validation and test scores\n",
        "val_scores = [scores[0] for scores in f1_by_model.values()]\n",
        "test_scores = [scores[1] for scores in f1_by_model.values()]\n",
        "\n",
        "# Define colors for the bars\n",
        "colors_val = ['grey' if f1 != max(val_scores) else 'red' for f1 in val_scores]\n",
        "colors_test = ['grey' if f1 != max(test_scores) else 'red' for f1 in test_scores]\n",
        "\n",
        "# Create subplots\n",
        "fig, ax = plt.subplots()\n",
        "\n",
        "# Define bar width and positions\n",
        "bar_width = 0.35\n",
        "index = np.arange(len(f1_by_model))\n",
        "\n",
        "# Plot validation scores\n",
        "bars_val = ax.bar(index, val_scores, bar_width, color=colors_val, label='Validation')\n",
        "\n",
        "# Plot test scores\n",
        "bars_test = ax.bar(index + bar_width, test_scores, bar_width, color=colors_test, label='Test', alpha=0.7)\n",
        "\n",
        "# Add value labels inside each bar\n",
        "for bar in bars_val + bars_test:\n",
        "    yval = bar.get_height()\n",
        "    ax.text(bar.get_x() + bar.get_width() / 2, yval * 0.9, round(yval, 4), ha='center', va='center', rotation='vertical', color='white')\n",
        "\n",
        "# Rotate x-axis labels for better readability\n",
        "plt.xticks(index + bar_width / 2, f1_by_model.keys(), rotation=90)\n",
        "\n",
        "# Add title and legend\n",
        "plt.title(\"Validation and Test F1 score by model\")\n",
        "plt.legend()\n",
        "\n",
        "# Show plot\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XagHI5QV1iAE"
      },
      "source": [
        "# Generar solución para el torneo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "id": "PgPBu9b11mf0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 0: Loss 1.0956376791000366\n",
            "Epoch 10: Loss 1.098576545715332\n",
            "Epoch 20: Loss 1.0505106449127197\n",
            "Epoch 30: Loss 0.7685238718986511\n",
            "Epoch 40: Loss 0.6667629480361938\n",
            "Epoch 50: Loss 0.45313823223114014\n",
            "Epoch 60: Loss 0.35944318771362305\n",
            "Epoch 70: Loss 0.32189396023750305\n",
            "Epoch 80: Loss 0.27289557456970215\n",
            "Epoch 90: Loss 0.25731411576271057\n",
            "\n",
            "\n",
            "MODEL VALIDATION:\n",
            "\n",
            "Validation F1 score: 0.8692957746478873\n",
            "\n",
            "\n",
            "MODEL TEST:\n",
            "\n",
            "Test F1 score: 0.8818458417849898\n"
          ]
        }
      ],
      "source": [
        "model = Convolucional_Droput(\n",
        "    dataset.num_node_features,\n",
        "    1024,\n",
        "    dataset.num_classes\n",
        ")\n",
        "\n",
        "train_model(model, \"Convolucional Dropout\", data)\n",
        "\n",
        "dataset.create_test_json(model, 'pred_labels.json', device='cuda')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
